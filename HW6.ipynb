{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEx3M_MjizK3"
      },
      "source": [
        "# üëÄ WARNING üêà\n",
        "\n",
        "\n",
        "### ‚ö†Ô∏è Important Setup Instructions\n",
        "\n",
        "Before you begin this homework, please note that all tasks were tested in Google Colab. It's crucial to follow the setup steps below to ensure that your environment is configured correctly. You will require a GPU for some of the tasks, so please make sure to adjust your Colab settings accordingly.\n",
        "\n",
        "#### Setup Steps:\n",
        "\n",
        "1. Use a GPU runtime to accelerate the training process of the CNN and proper compile:\n",
        "   - In Google Colab, click on ‚ÄòRuntime‚Äô.\n",
        "   - Select ‚ÄòChange runtime type‚Äô.\n",
        "   - Choose ‚ÄòGPU‚Äô from the hardware accelerator dropdown menu.\n",
        "2. Install necessary libraries and dependencies as outlined in the provided code snippets.\n",
        "3. Execute all code cells in the order they are presented to avoid dependency issues.\n",
        "\n",
        "#### Installation Commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os09aqKPliMb",
        "outputId": "a3df5531-892e-4cd3-9967-b7055c36c46c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
        "!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
        "!ldconfig \"/usr/lib64-nvidia\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhIA-h5n5n04",
        "outputId": "dcfefb37-e248-43ab-f113-c9b002187906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorrt in /usr/local/lib/python3.10/dist-packages (8.6.1.post1)\n",
            "Requirement already satisfied: torch_tensorrt in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.15.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.16.3)\n",
            "Requirement already satisfied: maturin in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torch<2.1,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from torch_tensorrt) (2.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from maturin) (2.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.1,>=2.0.1->torch_tensorrt) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.1,>=2.0.1->torch_tensorrt) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0.1->torch_tensorrt) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0.1->torch_tensorrt) (17.0.6)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.1,>=2.0.1->torch_tensorrt) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorrt torch_tensorrt onnx onnxruntime maturin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "jpHw8JdPENo4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3ea494-0784-4268-bc66-659bf8ad8e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1minfo:\u001b[0m downloading installer\n",
            "\u001b[1minfo: \u001b[mprofile set to 'default'\n",
            "\u001b[1minfo: \u001b[mdefault host triple is x86_64-unknown-linux-gnu\n",
            "\u001b[1minfo: \u001b[msyncing channel updates for 'stable-x86_64-unknown-linux-gnu'\n",
            "\u001b[1minfo: \u001b[mlatest update on 2023-12-07, rust version 1.74.1 (a28077b28 2023-12-04)\n",
            "\u001b[1minfo: \u001b[mdownloading component 'cargo'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'clippy'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'rust-docs'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'rust-std'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'rustc'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'rustfmt'\n",
            "\u001b[1minfo: \u001b[minstalling component 'cargo'\n",
            "\u001b[1minfo: \u001b[minstalling component 'clippy'\n",
            "\u001b[1minfo: \u001b[minstalling component 'rust-docs'\n",
            " 14.4 MiB /  14.4 MiB (100 %)   1.3 MiB/s in  8s ETA:  0s\n",
            "\u001b[1minfo: \u001b[minstalling component 'rust-std'\n",
            " 25.8 MiB /  25.8 MiB (100 %)   9.9 MiB/s in  3s ETA:  0s\n",
            "\u001b[1minfo: \u001b[minstalling component 'rustc'\n",
            " 58.2 MiB /  58.2 MiB (100 %)  11.0 MiB/s in  5s ETA:  0s\n",
            "\u001b[1minfo: \u001b[minstalling component 'rustfmt'\n",
            "\u001b[1minfo: \u001b[mdefault toolchain set to 'stable-x86_64-unknown-linux-gnu'\n",
            "\n",
            "  \u001b[1m\u001b[32mstable-x86_64-unknown-linux-gnu installed\u001b[m - rustc 1.74.1 (a28077b28 2023-12-04)\n",
            "\n",
            "\u001b[1m\n",
            "Rust is installed now. Great!\n",
            "\u001b[m\n",
            "To get started you may need to restart your current shell.\n",
            "This would reload your \u001b[1mPATH\u001b[m environment variable to include\n",
            "Cargo's bin directory ($HOME/.cargo/bin).\n",
            "\n",
            "To configure your current shell, run:\n",
            "source \"$HOME/.cargo/env\"\n"
          ]
        }
      ],
      "source": [
        "!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "_4cwr9FYFBH-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PATH'] += \":/root/.cargo/bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBJjzFHIFQkj",
        "outputId": "9c5eef19-7013-40cb-a9aa-2e5b709c2468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cargo 1.74.1 (ecb9851af 2023-10-18)\n"
          ]
        }
      ],
      "source": [
        "!cargo --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7CbAqtMlZtL"
      },
      "source": [
        "# HSE 2023: Mathematical Methods for Data Analysis\n",
        "\n",
        "# Homework 6 (Bonus)\n",
        "\n",
        "**Author: Alexander Kalashnikov**\n",
        "\n",
        "## Introduction\n",
        "Welcome to an exciting journey through the realms of machine learning and system integration, where we will tackle a fascinating challenge: building a Convolutional Neural Network (CNN) designed to recognize time from images of digital clocks. This task not only covers the design and training of neural networks but also extends into the world of production-level deployment. We'll dive into converting a trained model into various runtimes, and you'll get hands-on experience with implementing model inference in Rust‚Äîa language renowned for its performance and safety.\n",
        "\n",
        "<img src=\"./images/1.png\">\n",
        "\n",
        "---\n",
        "\n",
        "<div align=\"center\"><b> Your mission is to train a model that can look at such images and tell us the time displayed. </b></div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kaN5zcloA3r"
      },
      "source": [
        "# Load data\n",
        "\n",
        "Let's begin by downloading the dataset required for this homework. The dataset contains the images that we will use to train our model.\n",
        "\n",
        "**Follow the commands below to download and extract the dataset into your working environment:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmBGcsb0oCKP",
        "outputId": "4ed2a511-1b84-44ca-eb93-7efbf89861fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZLKpoYcMVBVgZBq2jvB23zR4yHClVfUd\n",
            "To: /content/timer_dataset.zip\n",
            "100% 18.9M/18.9M [00:00<00:00, 37.0MB/s]\n",
            "Downloaded data into ./timer_dataset\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1ZLKpoYcMVBVgZBq2jvB23zR4yHClVfUd && unzip -q -o timer_dataset.zip\n",
        "!echo \"Downloaded data into ./timer_dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB8gsGPZdu1a"
      },
      "source": [
        "### Below are two utility functions for the start:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aKCPA-3ElS_k"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h6qhQPcElXUC"
      },
      "outputs": [],
      "source": [
        "def read_image(image_path: str) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Reads an image from a specified file path and convert it to RGB format.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): The path to the image file.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The image in RGB format.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return image\n",
        "\n",
        "\n",
        "def visualize(**images) -> None:\n",
        "    \"\"\"\n",
        "    Plots images in one row.\n",
        "\n",
        "    Args:\n",
        "        **images: Variable length keyword arguments. Each key-value pair should be\n",
        "                  the name of the image and the image data respectively.\n",
        "\n",
        "    \"\"\"\n",
        "    n = len(images)\n",
        "\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fpTc3CwG-Jt"
      },
      "source": [
        "## [Task 1] Exploratory Data Analysis (EDA) - 0.5 Point\n",
        "\n",
        "### Objective:\n",
        "Perform an exploratory data analysis (EDA) on the provided dataset to understand its structure, contents, and the data you'll be working with.\n",
        "\n",
        "### Instructions:\n",
        "\n",
        "1. **Verify Dataset Integrity:**\n",
        "   - Check dataset structure.\n",
        "   - Check the number of files in the dataset.\n",
        "\n",
        "2. **Understand File Distribution:**\n",
        "   - List the first few image filenames to get a sense of the naming convention.\n",
        "   - Review the targets file to understand the association between images and their labels.\n",
        "\n",
        "3. **Read Targets:**\n",
        "   - Use pandas to read the targets file into a DataFrame.\n",
        "   - Ensure the DataFrame is correctly structured with columns for both the target and the filename.\n",
        "\n",
        "4. **Data Visualization:**\n",
        "   - Use the `read_image` function to read a sample image from the dataset.\n",
        "   - Visualize the sample image using the `visualize` function.\n",
        "   - Map this sample image to the corresponding target in targets DataFrame printing both.\n",
        "\n",
        "5. **Initial Data Insights:**\n",
        "   - Report the size of the dataset (number of images).\n",
        "   - Provide a brief summary of the target variable distribution."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "5EMFv-gChPUp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ysZmYzuVdu1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "outputId": "46407eec-c917-4cce-973c-b56d1e80cf5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö: 1296\n",
            "–ü–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: ['ff6802020121ffff.png', 'ff1808caa088fcff.png', 'ff1a008262007eff.png', 'ff0800a81808cfff.png', 'ff1808082808ffff.png']\n",
            "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ DataFrame —Ü–µ–ª–µ–π:\n",
            "   target              filename\n",
            "0  21:57  ff1006a258017fff.png\n",
            "1  19:52  ff1006828880feff.png\n",
            "2  12:16  ff1800a81888cfff.png\n",
            "3  23:49  ff18088870087fff.png\n",
            "4  11:16  ff1800a81828ffff.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ò–º—è —Ñ–∞–π–ª–∞ –æ–±—Ä–∞–∑—Ü–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: ff1006a258017fff.png\n",
            "–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∞—è –º–µ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–∏: 21:57\n"
          ]
        }
      ],
      "source": [
        "# ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "def read_image(image_path: str) -> np.ndarray:\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return image\n",
        "\n",
        "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "def visualize(**images) -> None:\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(16, 5))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤\n",
        "dataset_path = './timer_dataset/images'  # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø—É—Ç—å –∫ –≤–∞—à–µ–º—É –Ω–∞–±–æ—Ä—É –¥–∞–Ω–Ω—ã—Ö –≤–µ—Ä–Ω—ã–π\n",
        "image_files = [img for img in os.listdir(dataset_path) if img.endswith('.png')]\n",
        "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö: {len(image_files)}\")\n",
        "\n",
        "# –°–ø–∏—Å–æ–∫ –ø–µ—Ä–≤—ã—Ö –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
        "print(\"–ü–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:\", image_files[:5])\n",
        "\n",
        "# –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ —Ü–µ–ª–µ–π (targets)\n",
        "targets_df = pd.read_csv('./timer_dataset/targets.txt', delimiter=' -> ', engine='python', names=['target', 'filename'])\n",
        "print(\"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ DataFrame —Ü–µ–ª–µ–π:\\n\", targets_df.head())\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–∑—Ü–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "sample_image_path = os.path.join(dataset_path, targets_df['filename'].iloc[0])\n",
        "sample_image = read_image(sample_image_path)\n",
        "visualize(sample_image=sample_image)\n",
        "\n",
        "# –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –æ–±—Ä–∞–∑–µ—Ü –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π —Ü–µ–ª—å—é\n",
        "sample_target = targets_df[targets_df['filename'] == targets_df['filename'].iloc[0]]['target'].iloc[0]\n",
        "print(\"–ò–º—è —Ñ–∞–π–ª–∞ –æ–±—Ä–∞–∑—Ü–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\", targets_df['filename'].iloc[0])\n",
        "print(\"–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∞—è –º–µ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–∏:\", sample_target)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nieGs50xnglc"
      },
      "source": [
        "## [Task 2] Implement `create_train_val_splits` Function - 0.25 Points\n",
        "\n",
        "### Objective:\n",
        "Write a Python function `create_train_val_splits` to divide a dataset into training and validation sets and save the result as a JSON file.\n",
        "\n",
        "### Requirements:\n",
        "\n",
        "- Read image names from a markup file (`markup_path`).\n",
        "- Split data into training and validation sets using the `val_ratio`.\n",
        "- Save the splits in JSON format to the specified `output_path`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oP1OSEU3mw2u"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def create_train_val_splits(\n",
        "    markup_path: str,\n",
        "    output_path: str,\n",
        "    val_ratio: float = 0.2,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Creates training and validation splits from a markup file and save them as a JSON file.\n",
        "\n",
        "    This function reads a markup file containing image names, splits the images into\n",
        "    training and validation sets, and then saves these sets to a specified JSON file.\n",
        "\n",
        "    Args:\n",
        "        markup_path (str): Path to the markup file with image names.\n",
        "        output_path (str): Path where the JSON file with train-validation splits will be saved.\n",
        "        val_ratio (float, optional): The proportion of the dataset to include\n",
        "        in the validation split. Defaults to 0.2.\n",
        "    \"\"\"\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "    with open(markup_path, 'r') as file:\n",
        "        data = file.readlines()\n",
        "\n",
        "    image_names = [line.split(' -> ')[1].strip() for line in data]\n",
        "\n",
        "    train_names, val_names = train_test_split(image_names, test_size=val_ratio)\n",
        "\n",
        "\n",
        "    splits = {\n",
        "        'train': train_names,\n",
        "        'val': val_names\n",
        "    }\n",
        "    with open(output_path, 'w') as file:\n",
        "        json.dump(splits, file, indent=4)\n",
        "\n",
        "\n",
        "markup_path = 'timer_dataset/targets.txt'\n",
        "output_path = 'timer_dataset/splits.json'\n",
        "create_train_val_splits(markup_path, output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vhi7Kf-dnyho"
      },
      "source": [
        "## [Task 3] Image Preprocessing and Augmentation - 1 Point\n",
        "\n",
        "<img src=\"./images/2.png\" width=\"60%\">\n",
        "\n",
        "### Objective:\n",
        "Implement functions to apply image augmentations and preprocessing for the images normalization and unification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf-CTUwjdu1b"
      },
      "source": [
        "### Part 1: Define Augmentation Functions\n",
        "\n",
        "\n",
        "- `get_training_augmentations(image_size: int) -> albu.Compose`: This function should construct a series of augmentation transforms for training images. You have the freedom to add any augmentations you find necessary to improve the training process. **However, ensure that every transformed image is resized to a square format with dimensions `image_size x image_size`.**\n",
        "\n",
        "\n",
        "- `get_validation_augmentations(image_size: int) -> albu.Compose`: This function will define a series of transformations for validation images. Validation transforms are typically less extensive than training transforms. They should normalize the image but should not include random transformations that would create variations in your validation data. Like the training augmentations, **all images should be resized to be square with the same width and height as specified by `image_size`.**\n",
        "\n",
        "Note that while you may introduce a variety of transformations for the training dataset to improve model robustness, all images, after augmentation, should maintain a square shape. This consistency is crucial for training stability and performance evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "S4p1_0KgnvuA"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, Literal\n",
        "\n",
        "import albumentations as albu\n",
        "\n",
        "\n",
        "def get_training_augmentations(image_size: int) -> albu.Compose:\n",
        "    \"\"\"\n",
        "    Constructs augmentation transform for training images.\n",
        "\n",
        "    Returns:\n",
        "        albu.Compose: augmentation transform\n",
        "    \"\"\"\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "    return albu.Compose([\n",
        "        albu.HorizontalFlip(p=0.5),  # —Å–ª—É—á–∞–π–Ω–æ–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ\n",
        "        albu.VerticalFlip(p=0.5),    # —Å–ª—É—á–∞–π–Ω–æ–µ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ\n",
        "        albu.Rotate(limit=45, p=0.5),  # —Å–ª—É—á–∞–π–Ω–æ–µ –≤—Ä–∞—â–µ–Ω–∏–µ –Ω–∞ —É–≥–æ–ª –¥–æ 45 –≥—Ä–∞–¥—É—Å–æ–≤\n",
        "        albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),  # —Å–ª—É—á–∞–π–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —è—Ä–∫–æ—Å—Ç–∏ –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç–∏\n",
        "        albu.Resize(image_size, image_size),  # –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "    ])\n",
        "\n",
        "def get_validation_augmentations(image_size: int) -> albu.Compose:\n",
        "    \"\"\"\n",
        "    Constructs augmentation transform for validation images.\n",
        "\n",
        "    Returns:\n",
        "        albu.Compose: augmentation transform\n",
        "    \"\"\"\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "    return albu.Compose([\n",
        "        albu.Resize(image_size, image_size),  # –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSD7B_OYdu1b"
      },
      "source": [
        "### Part 2: Implement `to_tensor` Function\n",
        "Implement the `to_tensor` function to reshape the input image to the required format for PyTorch models (**CxHxW** - channel first), which involves changing the order of dimensions and ensuring the data type is float32."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eGsYwaUaKWUR"
      },
      "outputs": [],
      "source": [
        "def to_tensor(x: np.ndarray, **kwargs) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Transposes an image array to the required shape for pytorch.\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray): image array.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: transposed image array\n",
        "    \"\"\"\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "    x = x.transpose(2, 0, 1)\n",
        "    if x.max() > 1:\n",
        "        x = x / 255.0\n",
        "    return x.astype('float32')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6sny98wdu1b"
      },
      "source": [
        "### Part 3: Implement `normalize_img` Function\n",
        "Write the `normalize_img` function to apply mean and standard deviation normalization to the image data, which is a common preprocessing step to standardize input data for model training.\n",
        "\n",
        "**Use the mean and the standard deviation values for the ImageNet dataset. Do not forget about the image normalization by maximum pixel value.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZIA5IC22KYyn"
      },
      "outputs": [],
      "source": [
        "def normalize_img(img: np.ndarray, **kwargs) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Normalizes image data.\n",
        "\n",
        "    Args:\n",
        "        img (np.ndarray): image array.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: normalized image array\n",
        "    \"\"\"\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "    mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
        "    std = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
        "\n",
        "    img = img / 255.0  # Ensure the pixel values are [0, 1]\n",
        "    img = (img - mean) / std\n",
        "\n",
        "    return img.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_img(img: np.ndarray, **kwargs) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Normalizes image data using the ImageNet mean and standard deviation.\n",
        "\n",
        "    Args:\n",
        "        img (np.ndarray): Image array in CxHxW format.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Normalized image array.\n",
        "    \"\"\"\n",
        "    img = img.transpose((2, 0, 1))  # –ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Å–µ–π HxWxC -> CxHxW\n",
        "\n",
        "    # Mean and std values for ImageNet data\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "    # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫ float\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "\n",
        "    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "    img = (img - mean[:, None, None]) / std[:, None, None]\n",
        "\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "rbOf_WWxr2hY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBMicBqadu1b"
      },
      "source": [
        "### Part 4: Construct Preprocessing Pipeline\n",
        "Combine the normalization and tensor transformation into a preprocessing pipeline with the `get_preprocessing` function, which should return an `albu.Compose` pipeline to be applied to image data before feeding it into the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hqoKpfZeKaN9"
      },
      "outputs": [],
      "source": [
        "def get_preprocessing() -> albu.Compose:\n",
        "    \"\"\"\n",
        "    Constructs preprocessing transform.\n",
        "\n",
        "    Args:\n",
        "        preprocessing_fn (Callable): data normalization function.\n",
        "\n",
        "    Returns:\n",
        "        albu.Compose: preprocessing transform\n",
        "    \"\"\"\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "    return albu.Compose([\n",
        "        albu.Lambda(image=normalize_img),\n",
        "        albu.Lambda(image=to_tensor)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs9A8kgKn28C"
      },
      "source": [
        "## [Task 4] Custom Dataset Class Implementation - 1 Point\n",
        "\n",
        "### Description:\n",
        "Construct a `TimerDataset` class extending PyTorch's `Dataset` class, capable of loading, processing, and augmenting timer images for model training.\n",
        "\n",
        "### Steps:\n",
        "1. Initialize the dataset with paths for images, markup, and splits, specifying data kind (train/validation), and optional augmentation and preprocessing functions.\n",
        "2. Load dataset splits from a JSON file and image-label pairs from a markup file.\n",
        "3. Implement `one_hot_encode` to encode targets as OH vectors.\n",
        "4. Implement `__getitem__` to load and preprocess images, and apply one-hot encoding to labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TpSIdGz-n0NC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba9b4032-8ffd-4a05-c8b4-a0c6929b2cc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import Callable, Literal\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class TimerDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom dataset class for loading and processing timer images.\n",
        "\n",
        "    This dataset class is designed to work with a specific format of markup file and\n",
        "    directory structure. It supports optional data augmentation and preprocessing.\n",
        "    Labels are one-hot encoded.\n",
        "\n",
        "    Args:\n",
        "        images_path (Path): Path to the directory containing images.\n",
        "        markup_path (Path): Path to the markup file containing image names and corresponding time labels.\n",
        "        splits_path (Path): Path to the JSON file containing train/validation splits.\n",
        "        kind (str): Type of dataset to load ('train' or 'validation').\n",
        "        augmentations (Callable, optional): A function/callable that applies data augmentation.\n",
        "        preprocessing (Callable, optional): A function/callable that applies preprocessing.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, images_path, markup_path, splits_path, kind, augmentations=Callable | None, preprocessing=Callable | None):\n",
        "        self.images_path = images_path\n",
        "        self.markup_path = markup_path\n",
        "        self.splits_path = splits_path\n",
        "        self.kind = kind\n",
        "        self.augmentations = augmentations\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏\n",
        "        with open(splits_path) as f:\n",
        "            self.splits = json.load(f)[kind]\n",
        "\n",
        "        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏\n",
        "        self.samples = []\n",
        "        with open(markup_path) as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split(' -> ')\n",
        "                if parts[1] in self.splits:\n",
        "                    self.samples.append((parts[1], self.parse_time(parts[0])))\n",
        "\n",
        "        if not self.samples:\n",
        "            raise RuntimeError(f\"–°–ø–∏—Å–æ–∫ samples –ø—É—Å—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª—ã {splits_path} –∏ {markup_path}.\")\n",
        "\n",
        "    def __len__(self):\n",
        "            return len(self.samples)\n",
        "\n",
        "    def parse_time(self, time_str: str):\n",
        "            hours, minutes = map(int, time_str.split(':'))\n",
        "            return hours, minutes\n",
        "\n",
        "    def one_hot_encode(self, time: tuple[int, int]) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        One-hot encodes the given time.\n",
        "\n",
        "        Args:\n",
        "            time (tuple[int, int]): A tuple containing hours and minutes.\n",
        "\n",
        "        Returns:\n",
        "            tuple[torch.Tensor, torch.Tensor]: One-hot encoded hour and minute tensors.\n",
        "        \"\"\"\n",
        "        # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "        hours, minutes = time\n",
        "        hour_label = torch.zeros(24)\n",
        "        minute_label = torch.zeros(60)\n",
        "        hour_label[hours] = 1\n",
        "        minute_label[minutes] = 1\n",
        "        return hour_label, minute_label\n",
        "\n",
        "    def __getitem__(self, idx: int) -> tuple[np.ndarray, tuple[int, int]]:\n",
        "        if idx >= len(self.samples):\n",
        "            raise IndexError(f\"–ò–Ω–¥–µ–∫—Å {idx} –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å —Ä–∞–∑–º–µ—Ä–æ–º {len(self.samples)}.\")\n",
        "\n",
        "        image_name, time = self.samples[idx]\n",
        "        image_path = self.images_path / image_name\n",
        "        image = cv2.imread(str(image_path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.augmentations:\n",
        "            augmented = self.augmentations(image=image)\n",
        "            image = augmented['image']\n",
        "\n",
        "        if self.preprocessing:\n",
        "            preprocessed = self.preprocessing(image=image)\n",
        "            image = preprocessed['image']\n",
        "\n",
        "        image = image.transpose(1, 2, 0)\n",
        "        hour_label, minute_label = self.one_hot_encode(time)\n",
        "\n",
        "        return image, (hour_label, minute_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_path = Path('timer_dataset/images')\n",
        "markup_path = Path('timer_dataset/targets.txt')\n",
        "splits_path = Path('timer_dataset/splits.json')\n"
      ],
      "metadata": {
        "id": "KA9_sNninuFb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojy6T3yFdu1c"
      },
      "source": [
        "### Testing:\n",
        "- Instantiate the `TimerDataset` class.\n",
        "- Retrieve and visualize a sample from the dataset to confirm correct loading and processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mW7XPjHKn4Q8"
      },
      "outputs": [],
      "source": [
        "# dataset = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "dataset = TimerDataset(\n",
        "    images_path=images_path,\n",
        "    markup_path=markup_path,\n",
        "    splits_path=splits_path,\n",
        "    kind='train',\n",
        "    augmentations=get_training_augmentations(224),\n",
        "    preprocessing=get_preprocessing()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, labels = dataset[0]\n",
        "image = image.transpose((1, 2, 0))  # –ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Å–µ–π –∏–∑ (C, H, W) –≤ (H, W, C)\n",
        "visualize(image=image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "sb7fNN7FoArZ",
        "outputId": "75c8c186-cdc8-4fe1-edd3-260c291e81ba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# –¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –ª–∏—Ü–µ–∑—Ä–µ—Ç—å –∫–≤–∞–¥—Ä–∞—Ç –ú–∞–ª–µ–≤–∏—á–∞, –ø–æ—Ç—Ä—è—Å–∞—é—â–µ. –ù–∞–≤–µ—Ä–Ω–æ–µ —Ç–∞–∫ –∏ –¥–æ–ª–∂–Ω–æ –±—ã–ª–æ –ø–æ–ª—É—á–∏—Ç—Å—è\n"
      ],
      "metadata": {
        "id": "8rn3B7ovtVQ6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "0kpMxgdNn5zl",
        "outputId": "ede0e515-031a-48f3-eb3c-4dc577a05e17"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "visualize(image=dataset[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B2jbM1ep2oy"
      },
      "source": [
        "## [Task 5] Two-Headed CNN Model Architecture - 1 Point\n",
        "\n",
        "<img src=\"./images/3.png\" width=\"65%\">\n",
        "\n",
        "### Description:\n",
        "Design a neural network with a shared backbone and two separate heads for predicting hours and minutes.\n",
        "\n",
        "### Steps:\n",
        "1. Use a pre-trained CNN from `torchvision` to retrieve images features.\n",
        "2. Add two new heads, one for hour classification and one for minute classification, each with its own fully connected layers.\n",
        "3. Implement the `forward` method to process input through the backbone and both heads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yT7p1gbkpzmU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class TwoHeadedCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    A neural network module with two heads,\n",
        "    designed for simultaneous hour and minute classification.\n",
        "\n",
        "    This module takes a backbone CNN model,\n",
        "    removes its last fully connected layer, and adds two separate\n",
        "    heads: one for hour classification and one for minute classification.\n",
        "\n",
        "    Args:\n",
        "        backbone (torch.nn.Module): A pre-trained CNN model to use as the backbone.\n",
        "        num_hour_classes (int, optional): Number of hour classes (default is 24).\n",
        "        num_minute_classes (int, optional): Number of minute classes (default is 60).\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        backbone: torch.nn.Module,\n",
        "        num_hour_classes: int = 24,\n",
        "        num_minute_classes: int = 60,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # –£–¥–∞–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
        "        self.features = nn.Sequential(*list(backbone.children())[:-1])\n",
        "\n",
        "        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–µ—Ä–µ–¥ –ø–æ—Å–ª–µ–¥–Ω–∏–º –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–º —Å–ª–æ–µ–º\n",
        "        if hasattr(backbone, 'fc'):\n",
        "            num_features = backbone.fc.in_features\n",
        "        elif hasattr(backbone, 'classifier'):\n",
        "            num_features = backbone.classifier[-1].in_features\n",
        "        else:\n",
        "            raise ValueError(\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏\")\n",
        "\n",
        "        # –ì–æ–ª–æ–≤–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —á–∞—Å–æ–≤\n",
        "        self.hour_head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_hour_classes)\n",
        "        )\n",
        "\n",
        "        # –ì–æ–ª–æ–≤–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–∏–Ω—É—Ç\n",
        "        self.minute_head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_minute_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Defines the forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor to the network.\n",
        "\n",
        "        Returns:\n",
        "            tuple[torch.Tensor, torch.Tensor]: The outputs from the hours head and minutes head.\n",
        "        \"\"\"\n",
        "        # Forward pass through the backbone model\n",
        "        x = self.features(x)\n",
        "\n",
        "        # –ï—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å –≤–∫–ª—é—á–∞–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —É—Å—Ä–µ–¥–Ω—è—é—â–∏–π —Å–ª–æ–π\n",
        "        # –ú—ã –¥–æ–ª–∂–Ω—ã —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –ø–ª–æ—Å–∫–∏–µ –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–¥–∞—á–µ–π –≤ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        hour_output = self.hour_head(x)\n",
        "        minute_output = self.minute_head(x)\n",
        "\n",
        "        return hour_output, minute_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "backbone_model = models.resnet18(pretrained=True)\n",
        "model = TwoHeadedCNN(backbone=backbone_model)\n",
        "\n",
        "# example\n",
        "x = torch.randn(1, 3, 224, 224)  # random\n",
        "hour_output, minute_output = model(x)\n",
        "print(hour_output.shape, minute_output.shape)  # True response: ([1, 24], [1, 60])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK4B-GuivF1V",
        "outputId": "9a79edb9-cfa7-498c-ff57-f16644e6f73a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:00<00:00, 160MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 24]) torch.Size([1, 60])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1ThcbCzdu1c"
      },
      "source": [
        "## [Task 6] Composite Loss Function - 0.5 Points\n",
        "\n",
        "### Description:\n",
        "Develop a loss function that computes the composite loss for a two-headed CNN model, accounting for both hour and minute predictions.\n",
        "\n",
        "### Steps:\n",
        "1. Complete the `composite_loss` function that accepts the model outputs and true labels for both hours and minutes.\n",
        "2. Use CrossEntropyLoss to calculate the loss for each head separately.\n",
        "3. Combine the individual losses into a single composite loss value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5FW16HPedu1c"
      },
      "outputs": [],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "\n",
        "def composite_loss(\n",
        "    model_output: tuple[torch.Tensor, torch.Tensor],\n",
        "    hour_labels: torch.Tensor,\n",
        "    minute_labels: torch.Tensor,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Calculates the composite loss for the two outputs of the model.\n",
        "\n",
        "    This function computes the CrossEntropyLoss for each output (hours and minutes)\n",
        "    and then combines them to create a composite loss.\n",
        "\n",
        "    Args:\n",
        "        model_output (tuple[torch.Tensor, torch.Tensor]): The outputs of the model,\n",
        "                                                          where the first tensor is hour predictions\n",
        "                                                          and the second tensor is minute predictions.\n",
        "        hour_labels (torch.Tensor): The true hour labels.\n",
        "        minute_labels (torch.Tensor): The true minute labels.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The composite loss value.\n",
        "    \"\"\"\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "    # —Åreate CrossEntropyLoss\n",
        "    loss_fn = CrossEntropyLoss()\n",
        "\n",
        "    # calculate loss\n",
        "    hour_loss = loss_fn(model_output[0], hour_labels)\n",
        "    minute_loss = loss_fn(model_output[1], minute_labels)\n",
        "\n",
        "    # avg\n",
        "    composite_loss = hour_loss + minute_loss\n",
        "\n",
        "    return composite_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0S5NqWhp6Z9"
      },
      "source": [
        "## [Task 7] Training Loop - 1.25 Points\n",
        "\n",
        "### Description:\n",
        "Set up the training loop for the model using the provided configuration. This will involve writing `train_epoch` and `valid_epoch` functions, as well as the `main` function to initialize the model and datasets and to orchestrate the training process.\n",
        "\n",
        "### Steps:\n",
        "1. `train_epoch`: Write a function to train the model for one epoch, using the DataLoader to fetch data, the model to make predictions, the loss function to compute the loss, and the optimizer to update the model parameters.\n",
        "2. `valid_epoch`: Write a function to validate the model for one epoch. It should also use the DataLoader to fetch data and the model to make predictions, but it should not perform any parameter updates.\n",
        "3. `main`: Implement the main function to load data, create model instances, and call the training and validation functions in a loop for the desired number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XXavMB9ap4ha"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import Callable, Any\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def train_epoch(\n",
        "    model: torch.nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    loss_fn: Callable,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    device: str | torch.device,\n",
        "    epoch: int,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Performs a single training epoch.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The neural network model to train.\n",
        "        dataloader (DataLoader): DataLoader for the training dataset.\n",
        "        loss_fn (Callable): Loss function used for training.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer for updating model weights.\n",
        "        device (str | torch.device): Device to which tensors will be moved ('cpu' or 'cuda').\n",
        "        epoch (int): Current epoch number.\n",
        "\n",
        "    Returns:\n",
        "        float: Average loss for this training epoch.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, (hour_labels, minute_labels) in tqdm(dataloader, desc=f\"Epoch {epoch + 1} Training\"):\n",
        "        images = images.to(device)\n",
        "        hour_labels = hour_labels.to(device)\n",
        "        minute_labels = minute_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hour_preds, minute_preds = model(images)\n",
        "        loss = loss_fn((hour_preds, minute_preds), hour_labels, minute_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def valid_epoch(\n",
        "    model: torch.nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    loss_fn: Callable,\n",
        "    device: str | torch.device,\n",
        "    epoch: int,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Performs a single validation epoch.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The neural network model to validate.\n",
        "        dataloader (DataLoader): DataLoader for the validation dataset.\n",
        "        loss_fn (Callable): Loss function used for validation.\n",
        "        device (str | torch.device): Device to which tensors will be moved ('cpu' or 'cuda').\n",
        "        epoch (int): Current epoch number.\n",
        "\n",
        "    Returns:\n",
        "        float: Average loss for this validation epoch.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for images, (hour_labels, minute_labels) in tqdm(dataloader, desc=f\"Epoch {epoch + 1} Validation\"):\n",
        "            images = images.to(device)\n",
        "            hour_labels = hour_labels.to(device)\n",
        "            minute_labels = minute_labels.to(device)\n",
        "\n",
        "            hour_preds, minute_preds = model(images)\n",
        "            loss = loss_fn((hour_preds, minute_preds), hour_labels, minute_labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def main(config: dict[str, Any]) -> torch.nn.Module:\n",
        "    \"\"\"\n",
        "    Main training loop for the model.\n",
        "\n",
        "    This function sets up datasets, dataloaders, model,\n",
        "    loss function, and optimizer based on the provided configuration.\n",
        "    It then runs the training and validation loops for a specified number of epochs.\n",
        "\n",
        "    Args:\n",
        "        config (dict[str, Any]): Configuration dictionary containing parameters for training.\n",
        "\n",
        "    Returns:\n",
        "        torch.nn.Module: Trained model.\n",
        "    \"\"\"\n",
        "    train_dataset = TimerDataset(\n",
        "        images_path=Path(config['images_path']),\n",
        "        markup_path=Path(config['markup_path']),\n",
        "        splits_path=Path(config['splits_path']),\n",
        "        kind='train',\n",
        "        augmentations=get_training_augmentations(config['image_size']),\n",
        "        preprocessing=get_preprocessing()\n",
        "    )\n",
        "\n",
        "    valid_dataset = TimerDataset(\n",
        "        images_path=Path(config['images_path']),\n",
        "        markup_path=Path(config['markup_path']),\n",
        "        splits_path=Path(config['splits_path']),\n",
        "        kind='val',\n",
        "        augmentations=None,\n",
        "        preprocessing=get_preprocessing()\n",
        "    )\n",
        "\n",
        "    # –°–æ–∑–¥–∞–Ω–∏–µ DataLoader'–æ–≤\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "\n",
        "    model = TwoHeadedCNN(models.resnet34(pretrained=True))\n",
        "    model.to(config['device'])\n",
        "\n",
        "    loss_fn = composite_loss\n",
        "\n",
        "    optimizer = Adam(model.parameters(), lr=config['learning_rate'])\n",
        "\n",
        "    for epoch in range(config['num_epochs']):\n",
        "        train_loss = train_epoch(\n",
        "            model, train_loader, loss_fn, optimizer, config['device'], epoch\n",
        "        )\n",
        "        valid_loss = valid_epoch(\n",
        "            model, valid_loader, loss_fn, config['device'], epoch\n",
        "        )\n",
        "\n",
        "        print(f\"Epoch {epoch + 1} Summary: Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcmb3rqQdu1d"
      },
      "source": [
        "## [Task 8] Model Training - 1 Point\n",
        "\n",
        "### Description:\n",
        "Execute the model training using the defined configuration and save the trained model's state for future use.\n",
        "\n",
        "### Steps:\n",
        "1. Create a configuration dictionary with all the necessary parameters for the training process, including paths for the dataset, number of epochs, learning rate, and device specification.\n",
        "2. Call the `main` function with this configuration to train the model.\n",
        "3. After training, save the model's state dictionary so that the trained model can be loaded and used for inference later.\n",
        "\n",
        "### Testing:\n",
        "- Run the training process with the specified configuration to ensure it completes without errors.\n",
        "- Confirm that the model's state dictionary is saved correctly by loading it and verifying that it contains the expected parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-uhsgh9ep9Cr",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de5465a-a17d-4654-fb7e-970a821ecf62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-f82ba261.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-f82ba261.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 230M/230M [00:02<00:00, 104MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83.3M/83.3M [00:00<00:00, 140MB/s]\n",
            "Epoch 1 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:14<00:00,  2.33it/s]\n",
            "Epoch 1 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 22.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Summary: Train Loss: 7.3192, Validation Loss: 7.3194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:08<00:00,  3.91it/s]\n",
            "Epoch 2 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 19.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Summary: Train Loss: 7.0363, Validation Loss: 7.3896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:08<00:00,  4.05it/s]\n",
            "Epoch 3 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 26.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Summary: Train Loss: 6.6037, Validation Loss: 7.3641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:08<00:00,  3.88it/s]\n",
            "Epoch 4 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 24.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Summary: Train Loss: 6.0225, Validation Loss: 7.4046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:08<00:00,  3.89it/s]\n",
            "Epoch 5 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 19.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Summary: Train Loss: 5.3819, Validation Loss: 7.3928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:08<00:00,  4.05it/s]\n",
            "Epoch 6 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 25.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Summary: Train Loss: 4.7515, Validation Loss: 7.6982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:08<00:00,  3.88it/s]\n",
            "Epoch 7 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 25.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Summary: Train Loss: 4.2330, Validation Loss: 7.6383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:08<00:00,  3.92it/s]\n",
            "Epoch 8 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 20.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Summary: Train Loss: 3.6528, Validation Loss: 7.9496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:08<00:00,  3.99it/s]\n",
            "Epoch 9 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 26.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Summary: Train Loss: 3.0818, Validation Loss: 7.9188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:08<00:00,  3.81it/s]\n",
            "Epoch 10 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 25.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Summary: Train Loss: 2.7215, Validation Loss: 9.2746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "\n",
        "# Basic configuration - adjust paths and parameters as needed\n",
        "config = {\n",
        "    \"image_size\": 224,\n",
        "    \"images_path\": \"timer_dataset/images\",\n",
        "    \"markup_path\": \"timer_dataset/targets.txt\",\n",
        "    \"splits_path\": \"timer_dataset/splits.json\",\n",
        "    \"batch_size\": 32,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"num_epochs\": 10,\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"backbone\": models.resnet152(weights=models.resnet.ResNet152_Weights.DEFAULT)\n",
        "}\n",
        "\n",
        "model = main(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ò–∑–Ω–∞—á–∞–ª—å–Ω–æ —è –∑–∞–ø—É—Å—Ç–∏–ª —Å–≤–æ–µ –≤–µ–¥—Ä–æ —Å lr = lr-10, –æ–¥–Ω–æ–π —ç–ø–æ—Ö–æ–π –∏ –º–∞–ª–µ–Ω—å–∫–∏–º –±–∞—Ç—á —Å–∞–π–∑–æ–º, –ø–æ–ª—É—á–∏–ª–∞—Å—å —á–µ–ø—É—Ö–∞, —Ä–µ—à–∏–ª —Ç–µ–ø–µ—Ä—å –ø–æ –¥—Ä—É–≥–æ–º—É"
      ],
      "metadata": {
        "id": "i51Ap-ffWiuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UPD: —Å –±–∞—Ç—á–µ–º 32 –∏ 25 —ç–ø–æ—Ö–∞–º–∏ —è –ø–µ—Ä–µ–æ–±—É—á–∏–ª—Å—è –∏ –º–æ–π –ª–æ—Å –æ–∫–∞–∑–∞–ª—Å—è –Ω–∞ –¥–Ω–µ, –¥–∞–≤–∞–π—Ç–µ –≤–Ω–µ—Å–µ–º –ø—Ä–∞–≤–∫–∏"
      ],
      "metadata": {
        "id": "x6PSwD2JZhDB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmzmk8peqI8b"
      },
      "source": [
        "### Save model's state dict: (if you wish)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8PN1319RqBZ9"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48KIk7kgqNRg"
      },
      "source": [
        "## [Task 9] Model Inference - 0.5 Points\n",
        "\n",
        "### Description:\n",
        "Create a function to perform inference on a single image using a pre-trained model, converting the output to a human-readable time format.\n",
        "\n",
        "### Steps:\n",
        "1. Define an `infer_torch` function that accepts an image in numpy array format, the trained model, and the target image size for preprocessing.\n",
        "2. Inside the function, apply the necessary validation augmentations and preprocessing to prepare the image for the model.\n",
        "3. Convert the preprocessed image to a PyTorch tensor and feed it into the model to obtain the predicted hour and minute.\n",
        "4. Convert the model's output to a time string in the format 'HH:MM'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "aT8vcQ5HqOno"
      },
      "outputs": [],
      "source": [
        "def infer_torch(image: np.ndarray, model: torch.nn.Module, image_size=64) -> str:\n",
        "    \"\"\"\n",
        "    Performs inference on a single image using a trained model.\n",
        "\n",
        "    This function applies validation augmentations and preprocessing to the image, converts it to a\n",
        "    PyTorch tensor, and then uses the model to predict the time. The function outputs the predicted\n",
        "    time as a string.\n",
        "\n",
        "    Args:\n",
        "        image (np.ndarray): The image to be processed and fed into the model.\n",
        "        model (torch.nn.Module): The trained model used for inference.\n",
        "        image_size (int, optional): The size to which the image will be resized.\n",
        "\n",
        "    Returns:\n",
        "        str: The predicted time as a string in the format 'HH:MM'.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Apply validation augmentations\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "\n",
        "    # Preprocess the image\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "\n",
        "    # Convert the image to a PyTorch tensor, add batch dimension, put on device\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "\n",
        "    # Predict using the model\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "\n",
        "    # Convert to time format\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "\n",
        "def infer_torch(image: np.ndarray, model: torch.nn.Module, image_size=64) -> str:\n",
        "    model.eval()\n",
        "\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])\n",
        "\n",
        "    image = transform(image).to(\"cuda\")\n",
        "    image = image.unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hour_preds, minute_preds = model(image)\n",
        "\n",
        "    hour = hour_preds.argmax(1).item()\n",
        "    minute = minute_preds.argmax(1).item()\n",
        "    predicted_time = f'{hour:02d}:{minute:02d}'\n",
        "\n",
        "    return predicted_time\n"
      ],
      "metadata": {
        "id": "cGZPYGUvVA0D"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WVRExmkdu1m"
      },
      "source": [
        "### Testing:\n",
        "- Use a sample image and a trained model to test the `infer_torch` function.\n",
        "- Display the original image and the predicted time to verify the function's output."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_path = 'example2.png'\n",
        "\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # convert to jpg\n",
        "\n",
        "predicted_time = infer_torch(image, model)\n",
        "\n",
        "def visualize(image):\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "visualize(image=image)\n",
        "print(\"Predicted Time:\", predicted_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "1wG4AlJVR5bA",
        "outputId": "4227d783-868d-4b07-f8de-8ed25ebf0cd4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Time: 06:54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –í–∞—É, –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ infer_torch —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–æ—Å—å. –ü–æ–∏–≥—Ä–∞–ª—Å—è —Å —ç–ø–æ—Ö–∞–º–∏ –∏ –±–∞—Ç—á–µ–º –∏ –Ω–∞ 7 –∑–∞–ø—É—Å–∫ –≤—Å—ë –æ–∫"
      ],
      "metadata": {
        "id": "-r_qB0nvTp32"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77w8e30PrP_p"
      },
      "source": [
        "## [Task 10] Model Evaluation - 1 Point\n",
        "\n",
        "### Description:\n",
        "Write a function to assess the model's performance on the validation set by calculating accuracy, which is the proportion of correct predictions to total predictions.\n",
        "\n",
        "### Steps:\n",
        "1. Define an `evaluate_model` function that receives the model, paths to splits and targets, and the directory containing images.\n",
        "2. Load the validation set splits and corresponding targets.\n",
        "3. Iterate over the validation set, performing inference and comparing the predicted time to the actual time.\n",
        "4. Tally the correct predictions and calculate the accuracy.\n",
        "\n",
        "**(!!) To achieve full points for this task, the model's accuracy on the validation set must exceed 0.9. Make sure to fine-tune your model and preprocessing steps to meet this benchmark.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpu1w9BJdu1m"
      },
      "source": [
        "**Two helper functions, special for you:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "W6JZOxzeqwuu"
      },
      "outputs": [],
      "source": [
        "def load_splits(splits_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Loads train/validation splits from a JSON file.\n",
        "\n",
        "    This function reads a JSON file specifying which images are in the training set\n",
        "    and which are in the validation set.\n",
        "\n",
        "    Args:\n",
        "        splits_path (str): The path to the JSON file containing the train/validation splits.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with keys 'train' and 'validation', each mapping to a list of image names.\n",
        "    \"\"\"\n",
        "    with open(splits_path, 'r') as file:\n",
        "        splits = json.load(file)\n",
        "    return splits\n",
        "\n",
        "\n",
        "def load_targets(targets_path: str) -> dict[str, str]:\n",
        "    \"\"\"\n",
        "    Loads target time labels for images from a file.\n",
        "\n",
        "    This function reads a file where each line contains a time label and an image name,\n",
        "    separated by ' -> '. It creates a dictionary mapping from image names to their corresponding\n",
        "    time labels.\n",
        "\n",
        "    Args:\n",
        "        targets_path (str): The path to the file containing the image names\n",
        "        and their corresponding time labels.\n",
        "\n",
        "    Returns:\n",
        "        dict[str, str]: A dictionary where keys are image names\n",
        "        and values are their corresponding time labels.\n",
        "    \"\"\"\n",
        "    targets = {}\n",
        "    with open(targets_path, 'r') as file:\n",
        "        for line in file:\n",
        "            time_str, image_name = line.strip().split(' -> ')\n",
        "            targets[image_name] = time_str\n",
        "    return targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Vov61_I0rR1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e769c0-c207-42a7-fb9a-c49bc0b50ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.0\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "def evaluate_model(\n",
        "    model: torch.nn.Module,\n",
        "    splits_path: str,\n",
        "    targets_path: str,\n",
        "    images_dir: str,\n",
        "    image_size: int = 64\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Evaluates model's accuracy on a validation set.\n",
        "\n",
        "    This function calculates the accuracy of the provided model by comparing its predictions\n",
        "    with the actual target times for each image in the validation set. It uses a specified\n",
        "    splits file to determine the images in the validation set and a targets file to get the\n",
        "    correct time labels.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The trained model to evaluate.\n",
        "        splits_path (str): Path to the JSON file containing the train/validation splits.\n",
        "        targets_path (str): Path to the file containing the image names and their corresponding time labels.\n",
        "        images_dir (str): Directory containing the images referenced in the targets file.\n",
        "        image_size (int, optional): Size to which the images should be resized.\n",
        "\n",
        "    Returns:\n",
        "        float: The accuracy of the model on the validation set.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    splits = load_splits(splits_path)\n",
        "    targets = load_targets(targets_path)\n",
        "\n",
        "    # Metrics initialization\n",
        "    correct_predictions = 0\n",
        "    total_predictions = len(splits['val'])\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    for image_name in splits['val']:\n",
        "        image_path = os.path.join(images_dir, image_name)\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        predicted_time = infer_torch(image, model, image_size)\n",
        "\n",
        "        actual_time = targets[image_name]\n",
        "        if predicted_time == actual_time:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return accuracy\n",
        "\n",
        "splits_path = 'timer_dataset/splits.json'\n",
        "targets_path = 'timer_dataset/targets.txt'\n",
        "images_dir = 'timer_dataset/images/'\n",
        "\n",
        "accuracy = evaluate_model(model, splits_path, targets_path, images_dir)\n",
        "print(\"\\nAccuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "dYhsNEZbdu1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "15b4228a-7efd-4936-b88d-5f5a2bcb5458"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-10f09d7b727a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Try again!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: Try again!"
          ]
        }
      ],
      "source": [
        "assert accuracy > 0.9, \"Try again!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSpK55pfdu1n"
      },
      "source": [
        "## [Task 11] Model Conversion and Speed Benchmarking - 1 Point\n",
        "\n",
        "### Description:\n",
        "Convert the trained model to different runtimes (JIT, ONNX, TensorRT) and benchmark the inference speed. Document the results in a comparative table.\n",
        "\n",
        "### Steps:\n",
        "1. Use the original PyTorch model (referred to as 'Vanilla') and perform inference speed testing.\n",
        "2. Convert the model using JIT compilation and measure the inference speed.\n",
        "3. Use the Torch Compile API to compile the model and benchmark the speed.\n",
        "4. Convert the model to TensorRT and test inference speed.\n",
        "5. Convert the model to ONNX and test inference speed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxr3akTsrqGg"
      },
      "source": [
        "**Vanilla**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c59VXLp2Gfl"
      },
      "outputs": [],
      "source": [
        "# Ensure, that the model in eval() mode, put it on the device\n",
        "model = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I_C8bSBrVoX"
      },
      "outputs": [],
      "source": [
        "%%timeit -n 500\n",
        "image = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "infer_torch(image, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc_39gQy3QPs"
      },
      "source": [
        "**Jit Tracing**\n",
        "\n",
        "Torch JIT tracing converts PyTorch models into an optimized, platform-independent format, boosting performance and simplifying deployment. It's useful for efficiently running models across different devices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MafeaWsG03n4"
      },
      "outputs": [],
      "source": [
        "# Create a dummy input for the tracing\n",
        "# ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "\n",
        "# Trace the model\n",
        "# ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42a-qoF73bhS"
      },
      "outputs": [],
      "source": [
        "%%timeit -n 500\n",
        "image = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "infer_torch(image, traced_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bajcqt3_rzon"
      },
      "source": [
        "**Torch Compile**\n",
        "\n",
        "`torch.compile` is a PyTorch feature that enhances performance by JIT-compiling PyTorch code into optimized kernels. This method speeds up code execution significantly with minimal changes to the existing codebase. It's a step beyond previous PyTorch compiler solutions like TorchScript and FX Tracing, offering more streamlined and efficient optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv_obvHwr6SZ"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "opt_model = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-w4JGdsr_74"
      },
      "outputs": [],
      "source": [
        "%%timeit -n 500\n",
        "image = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "infer_torch(image, opt_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpxhTy663w0W"
      },
      "source": [
        "**TensorRT**\n",
        "\n",
        "`TensorRT`, developed by NVIDIA, significantly enhances the speed and efficiency of deep learning models on GPUs. It uses advanced optimization techniques such as layer fusion and precision calibration to maximize throughput and reduce latency. Designed for cross-platform compatibility, it supports various frameworks and is particularly effective in production environments where high-performance inference is crucial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4kgYqV64Deq"
      },
      "outputs": [],
      "source": [
        "import torch_tensorrt\n",
        "\n",
        "# Create a dummy input for the compile\n",
        "dummy_input = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "\n",
        "# Compile the model\n",
        "tensorrt_model = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uc8psUc5WM2"
      },
      "outputs": [],
      "source": [
        "%%timeit -n 500\n",
        "image = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "infer_torch(image, tensorrt_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqX8i-UN9Owb"
      },
      "source": [
        "**ONNX**\n",
        "\n",
        "`ONNX (Open Neural Network Exchange)` is an open format designed to represent machine learning models. It enables models to be transferred between different frameworks, ensuring interoperability and flexibility. ONNX is widely used for model sharing and deployment across various platforms and tools, making it valuable for developers working in diverse environments or with multiple machine learning frameworks. Its ability to standardize model representation simplifies the process of model exchange and deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJ1-Ykq39InI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.onnx\n",
        "\n",
        "# Create a dummy input for the export\n",
        "dummy_input = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "\n",
        "# Export the model, saving it like \"model.onnx\"\n",
        "# ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXbdtezB-hFb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "\n",
        "\n",
        "def infer_onnx(\n",
        "    image: np.ndarray,\n",
        "    session: ort.InferenceSession,\n",
        "    image_size: int = 64\n",
        "  ) -> str:\n",
        "    \"\"\"\n",
        "    Performs inference on a single image using an ONNX model session.\n",
        "\n",
        "    This function applies validation augmentations and preprocessing to the image, converts it to the\n",
        "    format expected by the ONNX model, and then uses the session to predict the time. The function\n",
        "    outputs the predicted time as a string.\n",
        "\n",
        "    Args:\n",
        "        image (np.ndarray): The image to be processed and fed into the ONNX model.\n",
        "        session (ort.InferenceSession): The ONNX model inference session.\n",
        "        image_size (int, optional): The size to which the image will be resized.\n",
        "\n",
        "    Returns:\n",
        "        str: The predicted time as a string in the format 'HH:MM'.\n",
        "    \"\"\"\n",
        "    # Get ONNX model input_name\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "\n",
        "    # Apply validation augmentations\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "\n",
        "    # Preprocess the image\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "\n",
        "    # Convert the image to the batch expected by ONNX, cast to float\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "\n",
        "    # Predict using the ONNX session\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "\n",
        "    # Assuming the model returns two outputs: hour and minute\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "\n",
        "    # Convert to time format\n",
        "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "    return time_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0jHJv23GM9D"
      },
      "outputs": [],
      "source": [
        "# We initialize a session first\n",
        "session = ort.InferenceSession(\"model.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H7yiLncCQ_-"
      },
      "outputs": [],
      "source": [
        "%%timeit -n 500\n",
        "image = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
        "infer_onnx(image, session=session)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5o5wGqfdu1o"
      },
      "source": [
        "### Fill the table:\n",
        "\n",
        "| Runtime   | Number of Loops | Mean Inference Time (ms) | Standard Deviation (ms) |\n",
        "|-----------|-----------------|--------------------------|-------------------------|\n",
        "| Vanilla   | 500             | TBD                      | TBD                     |\n",
        "| JIT       | 500             | TBD                      | TBD                     |\n",
        "| Compile   | 500             | TBD                      | TBD                     |\n",
        "| TensorRT  | 500             | TBD                      | TBD                     |\n",
        "| ONNX      | 500             | TBD                      | TBD                     |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgQOQBv6du1o"
      },
      "source": [
        "### Your comments on results:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSI8Pwgcdu1o"
      },
      "source": [
        "(0_0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBKQvEW8SpLC"
      },
      "source": [
        "## [Task 12] Rust - 3 Points\n",
        "\n",
        "<img src=\"./images/4.jpeg\" width=50%>\n",
        "\n",
        "### About Rust:\n",
        "Rust is a programming language known for its focus on safety and performance. It's designed to be memory safe, preventing common bugs seen in languages like C and C++. Rust achieves this through its unique ownership system, which manages memory and other resources at compile time, eliminating many runtime errors.\n",
        "\n",
        "Its performance is comparable to C++, making it suitable for systems programming and applications where speed is critical. Rust also offers modern features like zero-cost abstractions, guaranteed memory safety, and a friendly compiler with useful error messages, enhancing developer experience.\n",
        "\n",
        "Rust is increasingly popular in areas such as web assembly, embedded systems, and networking, as well as for building command-line tools and desktop applications. Its growing community and rich ecosystem of tools and libraries contribute to its rising adoption.\n",
        "\n",
        "\n",
        "### Suggested Materials:\n",
        "- \"Rust by Example\": A collection of runnable examples that illustrate various Rust concepts and standard libraries.\n",
        "- \"Rustlings\": A fun, instructive way to get accustomed to reading and writing Rust syntax through small exercises.\n",
        "- \"Maturin\": A tool specifically designed for creating Python extensions in Rust with ease. It integrates seamlessly with Cargo and PyPI, simplifying the process of building and distributing Rust-written Python modules. Ideal for enhancing Python with Rust‚Äôs performance and safety features, Maturin makes it straightforward to package and share Rust code as Python packages.\n",
        "\n",
        "### Why Infer in Rust:\n",
        "Rust is good for machine learning inference, offering safety and high performance. It avoids latency issues common with garbage collectors and its type system and concurrency model enable efficient, maintainable code. Rust's capabilities allow for serverless inference with lightweight binaries, addressing the slowness of large frameworks like PyTorch in cluster instances. It also reduces Python's performance overhead, a notable advantage given Python's Global Interpreter Lock (GIL) challenges. Rust's growing popularity in the machine learning ecosystem.\n",
        "\n",
        "Finally, Rust is cool!\n",
        "\n",
        "---\n",
        "\n",
        "### Description:\n",
        "The task involves enhancing a machine learning workflow by integrating Rust's performance capabilities with Python's flexibility. The goal is to use Rust for running an ONNX model inference, and then create Python bindings to utilize the Rust implementation. This hybrid approach aims to leverage Rust's performance and safety while maintaining the ease of use provided by Python.\n",
        "\n",
        "The project structure includes:\n",
        "```\n",
        ".\n",
        "‚îú‚îÄ‚îÄ Cargo.toml\n",
        "‚îú‚îÄ‚îÄ images\n",
        "‚îú‚îÄ‚îÄ HW6.ipynb\n",
        "‚îú‚îÄ‚îÄ model.onnx\n",
        "‚îú‚îÄ‚îÄ example.png\n",
        "‚îú‚îÄ‚îÄ src\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ lib.rs\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ main.rs\n",
        "‚îî‚îÄ‚îÄ timer_dataset\n",
        "```\n",
        "\n",
        "- An example image file `example.png` which could be used for testing the inference process.\n",
        "- A `model.onnx` file which is our converted model to be used for inference.\n",
        "- A `Cargo.toml` file indicating the Rust project's dependencies.\n",
        "- A source directory `src` containing the Rust source code:\n",
        "  - `lib.rs` which is a Rust library file containing shared logic or definitions.\n",
        "  - `main.rs` which is the Rust main file, containing the entry point of the Rust application.\n",
        "\n",
        "**The `.rs` files in the source directory are almost complete but contain errors that need to be fixed. After correcting these errors, you are expected to compile the Rust source into a binary. This binary will be a production-ready executable that performs the ONNX model inference.**\n",
        "\n",
        "**The second part of the task is to build Python bindings using `maturin`. These bindings will allow Python scripts to call the Rust binary and perform inference. The binding should provide an interface where Python code can pass the paths of the model and image files, and then receive the inference results. The results expected are a string representing the predicted outcome and a float64 value indicating the elapsed time of the model call in Rust.**\n",
        "\n",
        "### Steps:\n",
        "1. Debug and correct the Rust code provided in `.rs` files.\n",
        "2. Compile the corrected Rust code into a production-ready binary for ONNX model inference.\n",
        "3. Create Python bindings for the Rust binary to allow inference from Python, ensuring the binding returns the predicted time as a string and the elapsed time as a float64."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOMdSMvidu1o"
      },
      "source": [
        "### Part 1: Binary - 1 Point\n",
        "\n",
        "Compile a Rust binary that performs ONNX model inference and accurately predicts time from an image.\n",
        "\n",
        "Instructions:\n",
        "1. Compile the Rust binary using the provided command. Ensure all dependencies are correctly installed for a successful build.\n",
        "2. Run the binary with an image to perform inference. The program should output the time taken for inference and the predicted time.\n",
        "\n",
        "Criteria for Full Points:\n",
        " - The Rust binary compiles without errors.\n",
        " - Upon execution, the binary prints out the time taken for the inference process and the correct predicted time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "kqxt8F9UL3Ch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5103586c-aeda-43b6-f846-6fc6cd214211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[32m    Updating\u001b[0m crates.io index\n",
            "\u001b[1m\u001b[32m Downloading\u001b[0m crates ...\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m memoffset v0.9.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m digest v0.10.7\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m tinyvec v1.6.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m thiserror v1.0.51\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m xattr v1.1.3\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m walkdir v2.4.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m version_check v0.9.4\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m unindent v0.2.3\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m unicode-segmentation v1.10.1\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m unicode-normalization v0.1.22\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m unicode-ident v1.0.12\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m ucd-trie v0.1.6\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m typenum v1.17.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m transpose v0.2.2\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m tract-onnx-opl v0.20.22\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m tract-onnx v0.20.22\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m tract-nnef v0.20.22\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m tract-linalg v0.20.22\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m tract-hir v0.20.22\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m tract-data v0.20.22\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m tract-core v0.20.22\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m time-core v0.1.1\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m libc v0.2.151\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m time-macros v0.2.10\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m tinyvec_macros v0.1.1\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m errno v0.3.8\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m pyo3 v0.20.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m dyn-clone v1.0.16\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m pest_derive v2.7.5\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m downcast-rs v1.2.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m derive-new v0.5.9\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m cfg-if v1.0.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m bytes v1.5.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m anymap2 v0.13.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m liquid-derive v0.26.4\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m ppv-lite86 v0.2.17\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m pest_meta v2.7.5\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m pest_generator v2.7.5\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m pest v2.7.5\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m percent-encoding v2.3.1\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m paste v1.0.14\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m liquid-core v0.26.4\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m liquid v0.26.4\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m itoa v1.0.10\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m itertools v0.10.5\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m indoc v2.0.4\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m parking_lot v0.12.1\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m num-traits v0.2.17\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m num-integer v0.1.45\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m nom v7.1.3\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m miniz_oxide v0.7.1\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m heck v0.4.1\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m half v2.2.1\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m getrandom v0.2.11\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m generic-array v0.14.7\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m filetime v0.2.23\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m doc-comment v0.3.3\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m crc32fast v1.3.2\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m bit-set v0.5.3\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m autocfg v1.1.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m adler v1.0.2\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m lazy_static v1.4.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m crypto-common v0.1.6\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m cc v1.0.83\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m bitflags v2.4.1\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m once_cell v1.19.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m num-complex v0.4.4\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m ndarray v0.15.6\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m minimal-lexical v0.2.1\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m memmap2 v0.5.10\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m memchr v2.6.4\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m matrixmultiply v0.3.8\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m maplit v1.0.2\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m lock_api v0.4.11\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m linux-raw-sys v0.4.12\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m libm v0.2.8\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m kstring v2.0.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m hashbrown v0.11.2\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m anyhow v1.0.76\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m cpufeatures v0.2.11\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m ahash v0.7.7\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m aho-corasick v1.1.2\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m flate2 v1.0.28\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m time v0.3.23\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m thiserror-impl v1.0.51\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m target-lexicon v0.12.12\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m tar v0.4.40\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m syn v2.0.42\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m syn v1.0.109\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m string-interner v0.14.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m strength_reduce v0.2.4\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m static_assertions v1.1.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m smallvec v1.11.2\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m sha2 v0.10.8\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m serde_derive v1.0.193\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m serde v1.0.193\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m scopeguard v1.2.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m scan_fmt v0.2.6\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m same-file v1.0.6\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m rustix v0.38.28\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m rustfft v6.1.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m regex-syntax v0.8.2\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m regex-automata v0.4.3\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m regex v1.10.2\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m rawpointer v0.2.1\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m rand_distr v0.4.3\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m rand_core v0.6.4\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m rand_chacha v0.3.1\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m rand v0.8.5\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m quote v1.0.33\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m pyo3-macros-backend v0.20.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m pyo3-macros v0.20.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m pyo3-ffi v0.20.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m pyo3-build-config v0.20.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m prost-derive v0.11.9\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m prost v0.11.9\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m proc-macro2 v1.0.71\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m parking_lot_core v0.9.9\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m log v0.4.20\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m liquid-lib v0.26.4\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m bit-vec v0.6.3\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m byteorder v1.5.0\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m block-buffer v0.10.4\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m primal-check v0.3.3\n",
            "\u001b[1m\u001b[32m  Downloaded\u001b[0m either v1.9.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m autocfg v1.1.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m proc-macro2 v1.0.71\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m unicode-ident v1.0.12\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m libm v0.2.8\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m libc v0.2.151\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m quote v1.0.33\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m syn v2.0.42\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m cfg-if v1.0.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m once_cell v1.19.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m memchr v2.6.4\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m num-traits v0.2.17\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m thiserror v1.0.51\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m ucd-trie v0.1.6\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m version_check v0.9.4\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m getrandom v0.2.11\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m either v1.9.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m serde v1.0.193\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m thiserror-impl v1.0.51\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m serde_derive v1.0.193\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m pest v2.7.5\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m pest_meta v2.7.5\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m itertools v0.10.5\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m aho-corasick v1.1.2\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m num-integer v0.1.45\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m time-core v0.1.1\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m regex-syntax v0.8.2\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m anyhow v1.0.76\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m regex-automata v0.4.3\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m time-macros v0.2.10\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m pest_generator v2.7.5\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m itoa v1.0.10\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m static_assertions v1.1.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m time v0.3.23\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m kstring v2.0.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m pest_derive v2.7.5\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m regex v1.10.2\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m liquid-derive v0.26.4\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m ahash v0.7.7\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m anymap2 v0.13.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m doc-comment v0.3.3\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m syn v1.0.109\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m target-lexicon v0.12.12\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m liquid-core v0.26.4\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m matrixmultiply v0.3.8\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m smallvec v1.11.2\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m unicode-segmentation v1.10.1\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m tinyvec_macros v0.1.1\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m percent-encoding v2.3.1\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m liquid-lib v0.26.4\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m tinyvec v1.6.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m num-complex v0.4.4\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m rawpointer v0.2.1\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m same-file v1.0.6\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m walkdir v2.4.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m pyo3-build-config v0.20.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m cc v1.0.83\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m liquid v0.26.4\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m unicode-normalization v0.1.22\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m hashbrown v0.11.2\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m half v2.2.1\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m paste v1.0.14\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m minimal-lexical v0.2.1\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m nom v7.1.3\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m tract-linalg v0.20.22\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m string-interner v0.14.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m scan_fmt v0.2.6\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m ndarray v0.15.6\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m rustfft v6.1.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m maplit v1.0.2\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m strength_reduce v0.2.4\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m rustix v0.38.28\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m lazy_static v1.4.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m transpose v0.2.2\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m tract-data v0.20.22\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m derive-new v0.5.9\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m primal-check v0.3.3\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m bit-vec v0.6.3\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m log v0.4.20\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m dyn-clone v1.0.16\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m bitflags v2.4.1\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m linux-raw-sys v0.4.12\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m downcast-rs v1.2.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m crc32fast v1.3.2\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m bit-set v0.5.3\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m rand_core v0.6.4\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m ppv-lite86 v0.2.17\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m adler v1.0.2\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m miniz_oxide v0.7.1\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m rand_chacha v0.3.1\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m tract-core v0.20.22\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m xattr v1.1.3\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m pyo3-ffi v0.20.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m filetime v0.2.23\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m lock_api v0.4.11\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m parking_lot_core v0.9.9\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m tar v0.4.40\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m flate2 v1.0.28\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m rand v0.8.5\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m memoffset v0.9.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m heck v0.4.1\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m scopeguard v1.2.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m byteorder v1.5.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m tract-nnef v0.20.22\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m pyo3-macros-backend v0.20.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m rand_distr v0.4.3\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m prost-derive v0.11.9\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m pyo3 v0.20.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m bytes v1.5.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m prost v0.11.9\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m parking_lot v0.12.1\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m tract-onnx-opl v0.20.22\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m pyo3-macros v0.20.0\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m tract-hir v0.20.22\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m memmap2 v0.5.10\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m unindent v0.2.3\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m indoc v2.0.4\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m tract-onnx v0.20.22\n",
            "\u001b[1m\u001b[32m   Compiling\u001b[0m onnx_inference v0.1.0 (/content)\n",
            "\u001b[0m\u001b[1m\u001b[38;5;9merror\u001b[0m\u001b[0m\u001b[1m: expected `;`, found keyword `let`\u001b[0m\n",
            "\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/main.rs:29:31\u001b[0m\n",
            "\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[38;5;12m29\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    let start = Instant::now()\u001b[0m\n",
            "\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m                              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mhelp: add `;` here\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[38;5;12m30\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    let result = model.run(tvec!(image.into()))?;\u001b[0m\n",
            "\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m---\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12munexpected token\u001b[0m\n",
            "\n",
            "\u001b[0m\u001b[1m\u001b[38;5;9merror[E0433]\u001b[0m\u001b[0m\u001b[1m: failed to resolve: use of undeclared crate or module `image`\u001b[0m\n",
            "\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/main.rs:21:19\u001b[0m\n",
            "\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[38;5;12m21\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    let resized = image::imageops::resize(&img, 224, 224, ::image::imageops::FilterType::Triangle);\u001b[0m\n",
            "\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9muse of undeclared crate or module `image`\u001b[0m\n",
            "\n",
            "\u001b[0m\u001b[1m\u001b[38;5;9merror[E0433]\u001b[0m\u001b[0m\u001b[1m: failed to resolve: could not find `image` in the list of imported crates\u001b[0m\n",
            "\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/main.rs:21:61\u001b[0m\n",
            "\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[38;5;12m21\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    let resized = image::imageops::resize(&img, 224, 224, ::image::imageops::FilterType::Triangle);\u001b[0m\n",
            "\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m                                                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mcould not find `image` in the list of imported crates\u001b[0m\n",
            "\n",
            "\u001b[0m\u001b[1m\u001b[38;5;9merror[E0433]\u001b[0m\u001b[0m\u001b[1m: failed to resolve: use of undeclared crate or module `image`\u001b[0m\n",
            "\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/main.rs:20:15\u001b[0m\n",
            "\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[38;5;12m20\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    let img = image::open(\"example.png\").unwrap().to_rgb8();\u001b[0m\n",
            "\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9muse of undeclared crate or module `image`\u001b[0m\n",
            "\n",
            "\u001b[0m\u001b[1mFor more information about this error, try `rustc --explain E0433`.\u001b[0m\n",
            "\u001b[1m\u001b[31merror\u001b[0m\u001b[1m:\u001b[0m could not compile `onnx_inference` (bin \"binary\") due to 4 previous errors\n"
          ]
        }
      ],
      "source": [
        "!cargo build --bin binary -r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "3qGSDEwSYB08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c815ff-4d89-40b4-c7d1-4032ee6d3c1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./target/release/binary: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!./target/release/binary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEobhMEvdu1o"
      },
      "source": [
        "### Part 2: Python Binding - 2 Points\n",
        "\n",
        "Build a Python binding for the Rust-based ONNX inference engine and validate its functionality through a Python interface.\n",
        "\n",
        "Instructions:\n",
        "1. Use maturin to build the Python binding from the Rust implementation.\n",
        "2. Install the generated wheel using pip to make the binding available to Python.\n",
        "3. In Python, import the provided binding function and pass the paths of the ONNX model and an image file to it.\n",
        "4. Check that the function returns the correct prediction and the model's call time measured in Rust.\n",
        "\n",
        "Criteria for Full Points:\n",
        " - The Python binding compiles and installs without errors.\n",
        " - The Python code successfully calls the Rust inference engine and returns the correct prediction and elapsed time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmCJvcGgdu1o"
      },
      "source": [
        "**Binding build and library install:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPOCxt4vbsbx"
      },
      "outputs": [],
      "source": [
        "!maturin build -r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3tMxYuobzRX"
      },
      "outputs": [],
      "source": [
        "!pip install # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMQiPWWsdu1p"
      },
      "source": [
        "**Binding test:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hicxOvOkfZ-9"
      },
      "outputs": [],
      "source": [
        "from onnx_inference import run_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCQxriGefeRd"
      },
      "outputs": [],
      "source": [
        "predict, elapsed_time = run_model(\"model.onnx\", \"example.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kau4g_Atdu1p"
      },
      "outputs": [],
      "source": [
        "print(\"Time:\", predict, \"\\nElapsed time:\", elapsed_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM9JLQD0du1p"
      },
      "outputs": [],
      "source": [
        "assert predict == \"15:53\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwuHVZEmdu1p"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}