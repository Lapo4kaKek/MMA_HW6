{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEx3M_MjizK3"
      },
      "source": [
        "# 👀 WARNING 🐈\n",
        "\n",
        "\n",
        "### ⚠️ Important Setup Instructions\n",
        "\n",
        "Before you begin this homework, please note that all tasks were tested in Google Colab. It's crucial to follow the setup steps below to ensure that your environment is configured correctly. You will require a GPU for some of the tasks, so please make sure to adjust your Colab settings accordingly.\n",
        "\n",
        "#### Setup Steps:\n",
        "\n",
        "1. Use a GPU runtime to accelerate the training process of the CNN and proper compile:\n",
        "   - In Google Colab, click on ‘Runtime’.\n",
        "   - Select ‘Change runtime type’.\n",
        "   - Choose ‘GPU’ from the hardware accelerator dropdown menu.\n",
        "2. Install necessary libraries and dependencies as outlined in the provided code snippets.\n",
        "3. Execute all code cells in the order they are presented to avoid dependency issues.\n",
        "\n",
        "#### Installation Commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os09aqKPliMb",
        "outputId": "aaebc4af-8cf8-4c96-f8c4-75eb65b7880f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
        "!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
        "!ldconfig \"/usr/lib64-nvidia\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhIA-h5n5n04",
        "outputId": "6dbf6be7-3da9-4989-bab1-8c612be96ea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorrt\n",
            "  Downloading tensorrt-8.6.1.post1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch_tensorrt\n",
            "  Downloading torch_tensorrt-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime\n",
            "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting maturin\n",
            "  Downloading maturin-1.4.0-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.musllinux_1_1_x86_64.whl (10.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch<2.1,>=2.0.1 (from torch_tensorrt)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from maturin) (2.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch_tensorrt) (3.1.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<2.1,>=2.0.1->torch_tensorrt)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<2.1,>=2.0.1->torch_tensorrt)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch<2.1,>=2.0.1->torch_tensorrt)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<2.1,>=2.0.1->torch_tensorrt)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<2.1,>=2.0.1->torch_tensorrt)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch<2.1,>=2.0.1->torch_tensorrt)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch<2.1,>=2.0.1->torch_tensorrt)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch<2.1,>=2.0.1->torch_tensorrt)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch<2.1,>=2.0.1->torch_tensorrt)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch<2.1,>=2.0.1->torch_tensorrt)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch<2.1,>=2.0.1->torch_tensorrt)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch<2.1,>=2.0.1->torch_tensorrt)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.1,>=2.0.1->torch_tensorrt) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.1,>=2.0.1->torch_tensorrt) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0.1->torch_tensorrt) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch<2.1,>=2.0.1->torch_tensorrt)\n",
            "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.1,>=2.0.1->torch_tensorrt) (2.1.3)\n",
            "Building wheels for collected packages: tensorrt, lit\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-8.6.1.post1-py2.py3-none-any.whl size=17283 sha256=bc954eda433afed7924da2cfdf08f586afcc3a7faa841809e461efbef679eb39\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/c8/0e/b79b08e45752491b9acfdbd69e8a609e8b2ed7640dda5a3e59\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=087ab562eca33f6d63b0cda4ef1dcc2c8f654228d470d052779695cb631a1137\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
            "Successfully built tensorrt lit\n",
            "Installing collected packages: lit, tensorrt, onnx, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, maturin, humanfriendly, nvidia-cusolver-cu11, nvidia-cudnn-cu11, coloredlogs, onnxruntime, triton, torch, torch_tensorrt\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 lit-17.0.6 maturin-1.4.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 onnx-1.15.0 onnxruntime-1.16.3 tensorrt-8.6.1.post1 torch-2.0.1 torch_tensorrt-1.4.0 triton-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorrt torch_tensorrt onnx onnxruntime maturin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jpHw8JdPENo4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c2b5e4-043e-4598-c850-8ca1d59a79b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1minfo:\u001b[0m downloading installer\n",
            "\u001b[1minfo: \u001b[mprofile set to 'default'\n",
            "\u001b[1minfo: \u001b[mdefault host triple is x86_64-unknown-linux-gnu\n",
            "\u001b[1minfo: \u001b[msyncing channel updates for 'stable-x86_64-unknown-linux-gnu'\n",
            "\u001b[1minfo: \u001b[mlatest update on 2023-12-07, rust version 1.74.1 (a28077b28 2023-12-04)\n",
            "\u001b[1minfo: \u001b[mdownloading component 'cargo'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'clippy'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'rust-docs'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'rust-std'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'rustc'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'rustfmt'\n",
            "\u001b[1minfo: \u001b[minstalling component 'cargo'\n",
            "\u001b[1minfo: \u001b[minstalling component 'clippy'\n",
            "\u001b[1minfo: \u001b[minstalling component 'rust-docs'\n",
            " 14.4 MiB /  14.4 MiB (100 %)   2.1 MiB/s in  5s ETA:  0s\n",
            "\u001b[1minfo: \u001b[minstalling component 'rust-std'\n",
            " 25.8 MiB /  25.8 MiB (100 %)   9.7 MiB/s in  2s ETA:  0s\n",
            "\u001b[1minfo: \u001b[minstalling component 'rustc'\n",
            " 58.2 MiB /  58.2 MiB (100 %)  11.2 MiB/s in  5s ETA:  0s\n",
            "\u001b[1minfo: \u001b[minstalling component 'rustfmt'\n",
            "\u001b[1minfo: \u001b[mdefault toolchain set to 'stable-x86_64-unknown-linux-gnu'\n",
            "\n",
            "  \u001b[1m\u001b[32mstable-x86_64-unknown-linux-gnu installed\u001b[m - rustc 1.74.1 (a28077b28 2023-12-04)\n",
            "\n",
            "\u001b[1m\n",
            "Rust is installed now. Great!\n",
            "\u001b[m\n",
            "To get started you may need to restart your current shell.\n",
            "This would reload your \u001b[1mPATH\u001b[m environment variable to include\n",
            "Cargo's bin directory ($HOME/.cargo/bin).\n",
            "\n",
            "To configure your current shell, run:\n",
            "source \"$HOME/.cargo/env\"\n"
          ]
        }
      ],
      "source": [
        "!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_4cwr9FYFBH-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PATH'] += \":/root/.cargo/bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBJjzFHIFQkj",
        "outputId": "ae8018fb-d840-4590-bc5c-af86da50440d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cargo 1.74.1 (ecb9851af 2023-10-18)\n"
          ]
        }
      ],
      "source": [
        "!cargo --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7CbAqtMlZtL"
      },
      "source": [
        "# HSE 2023: Mathematical Methods for Data Analysis\n",
        "\n",
        "# Homework 6 (Bonus)\n",
        "\n",
        "**Author: Alexander Kalashnikov**\n",
        "\n",
        "## Introduction\n",
        "Welcome to an exciting journey through the realms of machine learning and system integration, where we will tackle a fascinating challenge: building a Convolutional Neural Network (CNN) designed to recognize time from images of digital clocks. This task not only covers the design and training of neural networks but also extends into the world of production-level deployment. We'll dive into converting a trained model into various runtimes, and you'll get hands-on experience with implementing model inference in Rust—a language renowned for its performance and safety.\n",
        "\n",
        "<img src=\"./images/1.png\">\n",
        "\n",
        "---\n",
        "\n",
        "<div align=\"center\"><b> Your mission is to train a model that can look at such images and tell us the time displayed. </b></div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kaN5zcloA3r"
      },
      "source": [
        "# Load data\n",
        "\n",
        "Let's begin by downloading the dataset required for this homework. The dataset contains the images that we will use to train our model.\n",
        "\n",
        "**Follow the commands below to download and extract the dataset into your working environment:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmBGcsb0oCKP",
        "outputId": "e848a880-7a7a-4e04-e1c2-f8fcc5f2e25e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZLKpoYcMVBVgZBq2jvB23zR4yHClVfUd\n",
            "To: /content/timer_dataset.zip\n",
            "100% 18.9M/18.9M [00:00<00:00, 72.0MB/s]\n",
            "Downloaded data into ./timer_dataset\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1ZLKpoYcMVBVgZBq2jvB23zR4yHClVfUd && unzip -q -o timer_dataset.zip\n",
        "!echo \"Downloaded data into ./timer_dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB8gsGPZdu1a"
      },
      "source": [
        "### Below are two utility functions for the start:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aKCPA-3ElS_k"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6qhQPcElXUC"
      },
      "outputs": [],
      "source": [
        "def read_image(image_path: str) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Reads an image from a specified file path and convert it to RGB format.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): The path to the image file.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The image in RGB format.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return image\n",
        "\n",
        "\n",
        "def visualize(**images) -> None:\n",
        "    \"\"\"\n",
        "    Plots images in one row.\n",
        "\n",
        "    Args:\n",
        "        **images: Variable length keyword arguments. Each key-value pair should be\n",
        "                  the name of the image and the image data respectively.\n",
        "\n",
        "    \"\"\"\n",
        "    n = len(images)\n",
        "\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fpTc3CwG-Jt"
      },
      "source": [
        "## [Task 1] Exploratory Data Analysis (EDA) - 0.5 Point\n",
        "\n",
        "### Objective:\n",
        "Perform an exploratory data analysis (EDA) on the provided dataset to understand its structure, contents, and the data you'll be working with.\n",
        "\n",
        "### Instructions:\n",
        "\n",
        "1. **Verify Dataset Integrity:**\n",
        "   - Check dataset structure.\n",
        "   - Check the number of files in the dataset.\n",
        "\n",
        "2. **Understand File Distribution:**\n",
        "   - List the first few image filenames to get a sense of the naming convention.\n",
        "   - Review the targets file to understand the association between images and their labels.\n",
        "\n",
        "3. **Read Targets:**\n",
        "   - Use pandas to read the targets file into a DataFrame.\n",
        "   - Ensure the DataFrame is correctly structured with columns for both the target and the filename.\n",
        "\n",
        "4. **Data Visualization:**\n",
        "   - Use the `read_image` function to read a sample image from the dataset.\n",
        "   - Visualize the sample image using the `visualize` function.\n",
        "   - Map this sample image to the corresponding target in targets DataFrame printing both.\n",
        "\n",
        "5. **Initial Data Insights:**\n",
        "   - Report the size of the dataset (number of images).\n",
        "   - Provide a brief summary of the target variable distribution."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "5EMFv-gChPUp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ysZmYzuVdu1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "outputId": "a0a42805-3e2d-4cb9-ef65-75533fbad82f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество изображений в наборе данных: 1296\n",
            "Первые несколько имен файлов изображений: ['ff181188aa80fbff.png', 'ff0820101010ffff.png', 'ff280a8a8a28ffff.png', 'ff5800e0f0a0ffff.png', 'ff5808080808ffff.png']\n",
            "Структура DataFrame целей:\n",
            "   target              filename\n",
            "0  21:57  ff1006a258017fff.png\n",
            "1  19:52  ff1006828880feff.png\n",
            "2  12:16  ff1800a81888cfff.png\n",
            "3  23:49  ff18088870087fff.png\n",
            "4  11:16  ff1800a81828ffff.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Имя файла образца изображения: ff1006a258017fff.png\n",
            "Соответствующая метка времени: 21:57\n"
          ]
        }
      ],
      "source": [
        "# ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "# Функция для чтения изображения\n",
        "def read_image(image_path: str) -> np.ndarray:\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return image\n",
        "\n",
        "# Функция для визуализации изображения\n",
        "def visualize(**images) -> None:\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(16, 5))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "# Проверяем структуру датасета и количество файлов\n",
        "dataset_path = './timer_dataset/images'  # Убедитесь, что путь к вашему набору данных верный\n",
        "image_files = [img for img in os.listdir(dataset_path) if img.endswith('.png')]\n",
        "print(f\"Количество изображений в наборе данных: {len(image_files)}\")\n",
        "\n",
        "# Список первых нескольких имен файлов изображений\n",
        "print(\"Первые несколько имен файлов изображений:\", image_files[:5])\n",
        "\n",
        "# Чтение файла целей (targets)\n",
        "targets_df = pd.read_csv('./timer_dataset/targets.txt', delimiter=' -> ', engine='python', names=['target', 'filename'])\n",
        "print(\"Структура DataFrame целей:\\n\", targets_df.head())\n",
        "\n",
        "# Визуализация образца изображения\n",
        "sample_image_path = os.path.join(dataset_path, targets_df['filename'].iloc[0])\n",
        "sample_image = read_image(sample_image_path)\n",
        "visualize(sample_image=sample_image)\n",
        "\n",
        "# Сопоставляем образец изображения с соответствующей целью\n",
        "sample_target = targets_df[targets_df['filename'] == targets_df['filename'].iloc[0]]['target'].iloc[0]\n",
        "print(\"Имя файла образца изображения:\", targets_df['filename'].iloc[0])\n",
        "print(\"Соответствующая метка времени:\", sample_target)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nieGs50xnglc"
      },
      "source": [
        "## [Task 2] Implement `create_train_val_splits` Function - 0.25 Points\n",
        "\n",
        "### Objective:\n",
        "Write a Python function `create_train_val_splits` to divide a dataset into training and validation sets and save the result as a JSON file.\n",
        "\n",
        "### Requirements:\n",
        "\n",
        "- Read image names from a markup file (`markup_path`).\n",
        "- Split data into training and validation sets using the `val_ratio`.\n",
        "- Save the splits in JSON format to the specified `output_path`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oP1OSEU3mw2u"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def create_train_val_splits(\n",
        "    markup_path: str,\n",
        "    output_path: str,\n",
        "    val_ratio: float = 0.2,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Creates training and validation splits from a markup file and save them as a JSON file.\n",
        "\n",
        "    This function reads a markup file containing image names, splits the images into\n",
        "    training and validation sets, and then saves these sets to a specified JSON file.\n",
        "\n",
        "    Args:\n",
        "        markup_path (str): Path to the markup file with image names.\n",
        "        output_path (str): Path where the JSON file with train-validation splits will be saved.\n",
        "        val_ratio (float, optional): The proportion of the dataset to include\n",
        "        in the validation split. Defaults to 0.2.\n",
        "    \"\"\"\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "    with open(markup_path, 'r') as file:\n",
        "        data = file.readlines()\n",
        "\n",
        "    image_names = [line.split(' -> ')[1].strip() for line in data]\n",
        "\n",
        "    train_names, val_names = train_test_split(image_names, test_size=val_ratio)\n",
        "\n",
        "\n",
        "    splits = {\n",
        "        'train': train_names,\n",
        "        'val': val_names\n",
        "    }\n",
        "    with open(output_path, 'w') as file:\n",
        "        json.dump(splits, file, indent=4)\n",
        "\n",
        "\n",
        "markup_path = 'timer_dataset/targets.txt'\n",
        "output_path = 'timer_dataset/splits.json'\n",
        "create_train_val_splits(markup_path, output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vhi7Kf-dnyho"
      },
      "source": [
        "## [Task 3] Image Preprocessing and Augmentation - 1 Point\n",
        "\n",
        "<img src=\"./images/2.png\" width=\"60%\">\n",
        "\n",
        "### Objective:\n",
        "Implement functions to apply image augmentations and preprocessing for the images normalization and unification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf-CTUwjdu1b"
      },
      "source": [
        "### Part 1: Define Augmentation Functions\n",
        "\n",
        "\n",
        "- `get_training_augmentations(image_size: int) -> albu.Compose`: This function should construct a series of augmentation transforms for training images. You have the freedom to add any augmentations you find necessary to improve the training process. **However, ensure that every transformed image is resized to a square format with dimensions `image_size x image_size`.**\n",
        "\n",
        "\n",
        "- `get_validation_augmentations(image_size: int) -> albu.Compose`: This function will define a series of transformations for validation images. Validation transforms are typically less extensive than training transforms. They should normalize the image but should not include random transformations that would create variations in your validation data. Like the training augmentations, **all images should be resized to be square with the same width and height as specified by `image_size`.**\n",
        "\n",
        "Note that while you may introduce a variety of transformations for the training dataset to improve model robustness, all images, after augmentation, should maintain a square shape. This consistency is crucial for training stability and performance evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "S4p1_0KgnvuA"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, Literal\n",
        "\n",
        "import albumentations as albu\n",
        "\n",
        "\n",
        "def get_training_augmentations(image_size: int) -> albu.Compose:\n",
        "    \"\"\"\n",
        "    Constructs augmentation transform for training images.\n",
        "\n",
        "    Returns:\n",
        "        albu.Compose: augmentation transform\n",
        "    \"\"\"\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "    return albu.Compose([\n",
        "        albu.HorizontalFlip(p=0.5),  # случайное горизонтальное отражение\n",
        "        albu.VerticalFlip(p=0.5),    # случайное вертикальное отражение\n",
        "        albu.Rotate(limit=45, p=0.5),  # случайное вращение на угол до 45 градусов\n",
        "        albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),  # случайные изменения яркости и контрастности\n",
        "        albu.Resize(image_size, image_size),  # изменение размера изображения\n",
        "    ])\n",
        "\n",
        "def get_validation_augmentations(image_size: int) -> albu.Compose:\n",
        "    \"\"\"\n",
        "    Constructs augmentation transform for validation images.\n",
        "\n",
        "    Returns:\n",
        "        albu.Compose: augmentation transform\n",
        "    \"\"\"\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "    return albu.Compose([\n",
        "        albu.Resize(image_size, image_size),  # изменение размера изображения\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSD7B_OYdu1b"
      },
      "source": [
        "### Part 2: Implement `to_tensor` Function\n",
        "Implement the `to_tensor` function to reshape the input image to the required format for PyTorch models (**CxHxW** - channel first), which involves changing the order of dimensions and ensuring the data type is float32."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eGsYwaUaKWUR"
      },
      "outputs": [],
      "source": [
        "def to_tensor(x: np.ndarray, **kwargs) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Transposes an image array to the required shape for pytorch.\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray): image array.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: transposed image array\n",
        "    \"\"\"\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "    x = x.transpose(2, 0, 1)\n",
        "    if x.max() > 1:\n",
        "        x = x / 255.0\n",
        "    return x.astype('float32')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6sny98wdu1b"
      },
      "source": [
        "### Part 3: Implement `normalize_img` Function\n",
        "Write the `normalize_img` function to apply mean and standard deviation normalization to the image data, which is a common preprocessing step to standardize input data for model training.\n",
        "\n",
        "**Use the mean and the standard deviation values for the ImageNet dataset. Do not forget about the image normalization by maximum pixel value.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZIA5IC22KYyn"
      },
      "outputs": [],
      "source": [
        "def normalize_img(img: np.ndarray, **kwargs) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Normalizes image data.\n",
        "\n",
        "    Args:\n",
        "        img (np.ndarray): image array.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: normalized image array\n",
        "    \"\"\"\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "    mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
        "    std = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
        "\n",
        "    img = img / 255.0  # Ensure the pixel values are [0, 1]\n",
        "    img = (img - mean) / std\n",
        "\n",
        "    return img.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_img(img: np.ndarray, **kwargs) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Normalizes image data using the ImageNet mean and standard deviation.\n",
        "\n",
        "    Args:\n",
        "        img (np.ndarray): Image array in CxHxW format.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Normalized image array.\n",
        "    \"\"\"\n",
        "    img = img.transpose((2, 0, 1))  # Перестановка осей HxWxC -> CxHxW\n",
        "\n",
        "    # Mean and std values for ImageNet data\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "    # Приведение типов изображения к float\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "\n",
        "    # Нормализация изображения\n",
        "    img = (img - mean[:, None, None]) / std[:, None, None]\n",
        "\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "rbOf_WWxr2hY"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBMicBqadu1b"
      },
      "source": [
        "### Part 4: Construct Preprocessing Pipeline\n",
        "Combine the normalization and tensor transformation into a preprocessing pipeline with the `get_preprocessing` function, which should return an `albu.Compose` pipeline to be applied to image data before feeding it into the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "hqoKpfZeKaN9"
      },
      "outputs": [],
      "source": [
        "def get_preprocessing() -> albu.Compose:\n",
        "    \"\"\"\n",
        "    Constructs preprocessing transform.\n",
        "\n",
        "    Args:\n",
        "        preprocessing_fn (Callable): data normalization function.\n",
        "\n",
        "    Returns:\n",
        "        albu.Compose: preprocessing transform\n",
        "    \"\"\"\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "    return albu.Compose([\n",
        "        albu.Lambda(image=normalize_img),\n",
        "        albu.Lambda(image=to_tensor)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs9A8kgKn28C"
      },
      "source": [
        "## [Task 4] Custom Dataset Class Implementation - 1 Point\n",
        "\n",
        "### Description:\n",
        "Construct a `TimerDataset` class extending PyTorch's `Dataset` class, capable of loading, processing, and augmenting timer images for model training.\n",
        "\n",
        "### Steps:\n",
        "1. Initialize the dataset with paths for images, markup, and splits, specifying data kind (train/validation), and optional augmentation and preprocessing functions.\n",
        "2. Load dataset splits from a JSON file and image-label pairs from a markup file.\n",
        "3. Implement `one_hot_encode` to encode targets as OH vectors.\n",
        "4. Implement `__getitem__` to load and preprocess images, and apply one-hot encoding to labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "TpSIdGz-n0NC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import Callable, Literal\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class TimerDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom dataset class for loading and processing timer images.\n",
        "\n",
        "    This dataset class is designed to work with a specific format of markup file and\n",
        "    directory structure. It supports optional data augmentation and preprocessing.\n",
        "    Labels are one-hot encoded.\n",
        "\n",
        "    Args:\n",
        "        images_path (Path): Path to the directory containing images.\n",
        "        markup_path (Path): Path to the markup file containing image names and corresponding time labels.\n",
        "        splits_path (Path): Path to the JSON file containing train/validation splits.\n",
        "        kind (str): Type of dataset to load ('train' or 'validation').\n",
        "        augmentations (Callable, optional): A function/callable that applies data augmentation.\n",
        "        preprocessing (Callable, optional): A function/callable that applies preprocessing.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, images_path, markup_path, splits_path, kind, augmentations=Callable | None, preprocessing=Callable | None):\n",
        "        self.images_path = images_path\n",
        "        self.markup_path = markup_path\n",
        "        self.splits_path = splits_path\n",
        "        self.kind = kind\n",
        "        self.augmentations = augmentations\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "        # Загрузка разделений на обучающую и валидационную выборки\n",
        "        with open(splits_path) as f:\n",
        "            self.splits = json.load(f)[kind]\n",
        "\n",
        "        # Загрузка разметки\n",
        "        self.samples = []\n",
        "        with open(markup_path) as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split(' -> ')\n",
        "                if parts[1] in self.splits:\n",
        "                    self.samples.append((parts[1], self.parse_time(parts[0])))\n",
        "\n",
        "        if not self.samples:\n",
        "            raise RuntimeError(f\"Список samples пуст. Проверьте файлы {splits_path} и {markup_path}.\")\n",
        "\n",
        "    def __len__(self):\n",
        "            return len(self.samples)\n",
        "\n",
        "    def parse_time(self, time_str: str):\n",
        "            hours, minutes = map(int, time_str.split(':'))\n",
        "            return hours, minutes\n",
        "\n",
        "    def one_hot_encode(self, time: tuple[int, int]) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        One-hot encodes the given time.\n",
        "\n",
        "        Args:\n",
        "            time (tuple[int, int]): A tuple containing hours and minutes.\n",
        "\n",
        "        Returns:\n",
        "            tuple[torch.Tensor, torch.Tensor]: One-hot encoded hour and minute tensors.\n",
        "        \"\"\"\n",
        "        # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "        hours, minutes = time\n",
        "        hour_label = torch.zeros(24)\n",
        "        minute_label = torch.zeros(60)\n",
        "        hour_label[hours] = 1\n",
        "        minute_label[minutes] = 1\n",
        "        return hour_label, minute_label\n",
        "\n",
        "    def __getitem__(self, idx: int) -> tuple[np.ndarray, tuple[int, int]]:\n",
        "        if idx >= len(self.samples):\n",
        "            raise IndexError(f\"Индекс {idx} вне диапазона для датасета с размером {len(self.samples)}.\")\n",
        "\n",
        "        image_name, time = self.samples[idx]\n",
        "        image_path = self.images_path / image_name\n",
        "        image = cv2.imread(str(image_path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.augmentations:\n",
        "            augmented = self.augmentations(image=image)\n",
        "            image = augmented['image']\n",
        "\n",
        "        if self.preprocessing:\n",
        "            preprocessed = self.preprocessing(image=image)\n",
        "            image = preprocessed['image']\n",
        "\n",
        "        image = image.transpose(1, 2, 0)\n",
        "        hour_label, minute_label = self.one_hot_encode(time)\n",
        "\n",
        "        return image, (hour_label, minute_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_path = Path('timer_dataset/images')\n",
        "markup_path = Path('timer_dataset/targets.txt')\n",
        "splits_path = Path('timer_dataset/splits.json')\n"
      ],
      "metadata": {
        "id": "KA9_sNninuFb"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojy6T3yFdu1c"
      },
      "source": [
        "### Testing:\n",
        "- Instantiate the `TimerDataset` class.\n",
        "- Retrieve and visualize a sample from the dataset to confirm correct loading and processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "mW7XPjHKn4Q8"
      },
      "outputs": [],
      "source": [
        "# dataset = # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "dataset = TimerDataset(\n",
        "    images_path=images_path,\n",
        "    markup_path=markup_path,\n",
        "    splits_path=splits_path,\n",
        "    kind='train',\n",
        "    augmentations=get_training_augmentations(224),\n",
        "    preprocessing=get_preprocessing()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, labels = dataset[0]\n",
        "image = image.transpose((1, 2, 0))  # Перестановка осей из (C, H, W) в (H, W, C)\n",
        "visualize(image=image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "sb7fNN7FoArZ",
        "outputId": "6488ba67-bcc7-4711-e4fc-f5c1136be935"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Теперь вы можете лицезреть квадрат Малевича, потрясающе. Наверное так и должно было получится\n"
      ],
      "metadata": {
        "id": "8rn3B7ovtVQ6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "0kpMxgdNn5zl",
        "outputId": "ede0e515-031a-48f3-eb3c-4dc577a05e17"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "visualize(image=dataset[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B2jbM1ep2oy"
      },
      "source": [
        "## [Task 5] Two-Headed CNN Model Architecture - 1 Point\n",
        "\n",
        "<img src=\"./images/3.png\" width=\"65%\">\n",
        "\n",
        "### Description:\n",
        "Design a neural network with a shared backbone and two separate heads for predicting hours and minutes.\n",
        "\n",
        "### Steps:\n",
        "1. Use a pre-trained CNN from `torchvision` to retrieve images features.\n",
        "2. Add two new heads, one for hour classification and one for minute classification, each with its own fully connected layers.\n",
        "3. Implement the `forward` method to process input through the backbone and both heads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "yT7p1gbkpzmU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class TwoHeadedCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    A neural network module with two heads,\n",
        "    designed for simultaneous hour and minute classification.\n",
        "\n",
        "    This module takes a backbone CNN model,\n",
        "    removes its last fully connected layer, and adds two separate\n",
        "    heads: one for hour classification and one for minute classification.\n",
        "\n",
        "    Args:\n",
        "        backbone (torch.nn.Module): A pre-trained CNN model to use as the backbone.\n",
        "        num_hour_classes (int, optional): Number of hour classes (default is 24).\n",
        "        num_minute_classes (int, optional): Number of minute classes (default is 60).\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        backbone: torch.nn.Module,\n",
        "        num_hour_classes: int = 24,\n",
        "        num_minute_classes: int = 60,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # Удаление последнего полносвязного слоя из основной модели\n",
        "        self.features = nn.Sequential(*list(backbone.children())[:-1])\n",
        "\n",
        "        # Получение количества признаков перед последним полносвязным слоем\n",
        "        if hasattr(backbone, 'fc'):\n",
        "            num_features = backbone.fc.in_features\n",
        "        elif hasattr(backbone, 'classifier'):\n",
        "            num_features = backbone.classifier[-1].in_features\n",
        "        else:\n",
        "            raise ValueError(\"Неизвестная архитектура модели\")\n",
        "\n",
        "        # Голова для классификации часов\n",
        "        self.hour_head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_hour_classes)\n",
        "        )\n",
        "\n",
        "        # Голова для классификации минут\n",
        "        self.minute_head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_minute_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Defines the forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor to the network.\n",
        "\n",
        "        Returns:\n",
        "            tuple[torch.Tensor, torch.Tensor]: The outputs from the hours head and minutes head.\n",
        "        \"\"\"\n",
        "        # Forward pass through the backbone model\n",
        "        x = self.features(x)\n",
        "\n",
        "        # Если основная модель включает адаптивный усредняющий слой\n",
        "        # Мы должны убедиться, что данные плоские перед передачей в полносвязный слой\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        hour_output = self.hour_head(x)\n",
        "        minute_output = self.minute_head(x)\n",
        "\n",
        "        return hour_output, minute_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "backbone_model = models.resnet18(pretrained=True)\n",
        "model = TwoHeadedCNN(backbone=backbone_model)\n",
        "\n",
        "# example\n",
        "x = torch.randn(1, 3, 224, 224)  # random\n",
        "hour_output, minute_output = model(x)\n",
        "print(hour_output.shape, minute_output.shape)  # True response: ([1, 24], [1, 60])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK4B-GuivF1V",
        "outputId": "5fcfb592-b109-4c6c-c0ba-fccdd8a8fb7c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 24]) torch.Size([1, 60])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1ThcbCzdu1c"
      },
      "source": [
        "## [Task 6] Composite Loss Function - 0.5 Points\n",
        "\n",
        "### Description:\n",
        "Develop a loss function that computes the composite loss for a two-headed CNN model, accounting for both hour and minute predictions.\n",
        "\n",
        "### Steps:\n",
        "1. Complete the `composite_loss` function that accepts the model outputs and true labels for both hours and minutes.\n",
        "2. Use CrossEntropyLoss to calculate the loss for each head separately.\n",
        "3. Combine the individual losses into a single composite loss value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "5FW16HPedu1c"
      },
      "outputs": [],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "\n",
        "def composite_loss(\n",
        "    model_output: tuple[torch.Tensor, torch.Tensor],\n",
        "    hour_labels: torch.Tensor,\n",
        "    minute_labels: torch.Tensor,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Calculates the composite loss for the two outputs of the model.\n",
        "\n",
        "    This function computes the CrossEntropyLoss for each output (hours and minutes)\n",
        "    and then combines them to create a composite loss.\n",
        "\n",
        "    Args:\n",
        "        model_output (tuple[torch.Tensor, torch.Tensor]): The outputs of the model,\n",
        "                                                          where the first tensor is hour predictions\n",
        "                                                          and the second tensor is minute predictions.\n",
        "        hour_labels (torch.Tensor): The true hour labels.\n",
        "        minute_labels (torch.Tensor): The true minute labels.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The composite loss value.\n",
        "    \"\"\"\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "    # сreate CrossEntropyLoss\n",
        "    loss_fn = CrossEntropyLoss()\n",
        "\n",
        "    # calculate loss\n",
        "    hour_loss = loss_fn(model_output[0], hour_labels)\n",
        "    minute_loss = loss_fn(model_output[1], minute_labels)\n",
        "\n",
        "    # avg\n",
        "    composite_loss = hour_loss + minute_loss\n",
        "\n",
        "    return composite_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0S5NqWhp6Z9"
      },
      "source": [
        "## [Task 7] Training Loop - 1.25 Points\n",
        "\n",
        "### Description:\n",
        "Set up the training loop for the model using the provided configuration. This will involve writing `train_epoch` and `valid_epoch` functions, as well as the `main` function to initialize the model and datasets and to orchestrate the training process.\n",
        "\n",
        "### Steps:\n",
        "1. `train_epoch`: Write a function to train the model for one epoch, using the DataLoader to fetch data, the model to make predictions, the loss function to compute the loss, and the optimizer to update the model parameters.\n",
        "2. `valid_epoch`: Write a function to validate the model for one epoch. It should also use the DataLoader to fetch data and the model to make predictions, but it should not perform any parameter updates.\n",
        "3. `main`: Implement the main function to load data, create model instances, and call the training and validation functions in a loop for the desired number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "XXavMB9ap4ha"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import Callable, Any\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def train_epoch(\n",
        "    model: torch.nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    loss_fn: Callable,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    device: str | torch.device,\n",
        "    epoch: int,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Performs a single training epoch.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The neural network model to train.\n",
        "        dataloader (DataLoader): DataLoader for the training dataset.\n",
        "        loss_fn (Callable): Loss function used for training.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer for updating model weights.\n",
        "        device (str | torch.device): Device to which tensors will be moved ('cpu' or 'cuda').\n",
        "        epoch (int): Current epoch number.\n",
        "\n",
        "    Returns:\n",
        "        float: Average loss for this training epoch.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, (hour_labels, minute_labels) in tqdm(dataloader, desc=f\"Epoch {epoch + 1} Training\"):\n",
        "        images = images.to(device)\n",
        "        hour_labels = hour_labels.to(device)\n",
        "        minute_labels = minute_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hour_preds, minute_preds = model(images)\n",
        "        loss = loss_fn((hour_preds, minute_preds), hour_labels, minute_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def valid_epoch(\n",
        "    model: torch.nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    loss_fn: Callable,\n",
        "    device: str | torch.device,\n",
        "    epoch: int,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Performs a single validation epoch.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The neural network model to validate.\n",
        "        dataloader (DataLoader): DataLoader for the validation dataset.\n",
        "        loss_fn (Callable): Loss function used for validation.\n",
        "        device (str | torch.device): Device to which tensors will be moved ('cpu' or 'cuda').\n",
        "        epoch (int): Current epoch number.\n",
        "\n",
        "    Returns:\n",
        "        float: Average loss for this validation epoch.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for images, (hour_labels, minute_labels) in tqdm(dataloader, desc=f\"Epoch {epoch + 1} Validation\"):\n",
        "            images = images.to(device)\n",
        "            hour_labels = hour_labels.to(device)\n",
        "            minute_labels = minute_labels.to(device)\n",
        "\n",
        "            hour_preds, minute_preds = model(images)\n",
        "            loss = loss_fn((hour_preds, minute_preds), hour_labels, minute_labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def main(config: dict[str, Any]) -> torch.nn.Module:\n",
        "    \"\"\"\n",
        "    Main training loop for the model.\n",
        "\n",
        "    This function sets up datasets, dataloaders, model,\n",
        "    loss function, and optimizer based on the provided configuration.\n",
        "    It then runs the training and validation loops for a specified number of epochs.\n",
        "\n",
        "    Args:\n",
        "        config (dict[str, Any]): Configuration dictionary containing parameters for training.\n",
        "\n",
        "    Returns:\n",
        "        torch.nn.Module: Trained model.\n",
        "    \"\"\"\n",
        "    train_dataset = TimerDataset(\n",
        "        images_path=Path(config['images_path']),\n",
        "        markup_path=Path(config['markup_path']),\n",
        "        splits_path=Path(config['splits_path']),\n",
        "        kind='train',\n",
        "        augmentations=get_training_augmentations(config['image_size']),\n",
        "        preprocessing=get_preprocessing()\n",
        "    )\n",
        "\n",
        "    valid_dataset = TimerDataset(\n",
        "        images_path=Path(config['images_path']),\n",
        "        markup_path=Path(config['markup_path']),\n",
        "        splits_path=Path(config['splits_path']),\n",
        "        kind='val',\n",
        "        augmentations=None,\n",
        "        preprocessing=get_preprocessing()\n",
        "    )\n",
        "\n",
        "    # Создание DataLoader'ов\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "\n",
        "    model = TwoHeadedCNN(models.resnet34(pretrained=True))\n",
        "    model.to(config['device'])\n",
        "\n",
        "    loss_fn = composite_loss\n",
        "\n",
        "    optimizer = Adam(model.parameters(), lr=config['learning_rate'])\n",
        "\n",
        "    for epoch in range(config['num_epochs']):\n",
        "        train_loss = train_epoch(\n",
        "            model, train_loader, loss_fn, optimizer, config['device'], epoch\n",
        "        )\n",
        "        valid_loss = valid_epoch(\n",
        "            model, valid_loader, loss_fn, config['device'], epoch\n",
        "        )\n",
        "\n",
        "        print(f\"Epoch {epoch + 1} Summary: Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcmb3rqQdu1d"
      },
      "source": [
        "## [Task 8] Model Training - 1 Point\n",
        "\n",
        "### Description:\n",
        "Execute the model training using the defined configuration and save the trained model's state for future use.\n",
        "\n",
        "### Steps:\n",
        "1. Create a configuration dictionary with all the necessary parameters for the training process, including paths for the dataset, number of epochs, learning rate, and device specification.\n",
        "2. Call the `main` function with this configuration to train the model.\n",
        "3. After training, save the model's state dictionary so that the trained model can be loaded and used for inference later.\n",
        "\n",
        "### Testing:\n",
        "- Run the training process with the specified configuration to ensure it completes without errors.\n",
        "- Confirm that the model's state dictionary is saved correctly by loading it and verifying that it contains the expected parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "-uhsgh9ep9Cr",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c6e56b4-48dc-4bcb-b98c-a36400f25e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Training: 100%|██████████| 33/33 [00:08<00:00,  3.90it/s]\n",
            "Epoch 1 Validation: 100%|██████████| 9/9 [00:00<00:00, 12.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Summary: Train Loss: 7.3544, Validation Loss: 7.3653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Training: 100%|██████████| 33/33 [00:11<00:00,  2.99it/s]\n",
            "Epoch 2 Validation: 100%|██████████| 9/9 [00:00<00:00, 16.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Summary: Train Loss: 7.1026, Validation Loss: 7.3033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Training: 100%|██████████| 33/33 [00:09<00:00,  3.38it/s]\n",
            "Epoch 3 Validation: 100%|██████████| 9/9 [00:00<00:00, 21.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Summary: Train Loss: 6.7504, Validation Loss: 7.4052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Training: 100%|██████████| 33/33 [00:09<00:00,  3.39it/s]\n",
            "Epoch 4 Validation: 100%|██████████| 9/9 [00:00<00:00, 20.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Summary: Train Loss: 6.2595, Validation Loss: 7.3399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Training: 100%|██████████| 33/33 [00:09<00:00,  3.48it/s]\n",
            "Epoch 5 Validation: 100%|██████████| 9/9 [00:00<00:00, 24.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Summary: Train Loss: 5.5833, Validation Loss: 7.4173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 Training: 100%|██████████| 33/33 [00:08<00:00,  3.68it/s]\n",
            "Epoch 6 Validation: 100%|██████████| 9/9 [00:00<00:00, 25.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Summary: Train Loss: 4.9271, Validation Loss: 7.5048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 Training: 100%|██████████| 33/33 [00:08<00:00,  3.80it/s]\n",
            "Epoch 7 Validation: 100%|██████████| 9/9 [00:00<00:00, 19.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Summary: Train Loss: 4.2279, Validation Loss: 7.3032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 Training: 100%|██████████| 33/33 [00:08<00:00,  3.80it/s]\n",
            "Epoch 8 Validation: 100%|██████████| 9/9 [00:00<00:00, 25.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Summary: Train Loss: 3.6987, Validation Loss: 7.4136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 Training: 100%|██████████| 33/33 [00:08<00:00,  3.73it/s]\n",
            "Epoch 9 Validation: 100%|██████████| 9/9 [00:00<00:00, 23.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Summary: Train Loss: 3.1259, Validation Loss: 7.5588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 Training: 100%|██████████| 33/33 [00:08<00:00,  3.87it/s]\n",
            "Epoch 10 Validation: 100%|██████████| 9/9 [00:00<00:00, 21.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Summary: Train Loss: 2.5699, Validation Loss: 7.7772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "\n",
        "# Basic configuration - adjust paths and parameters as needed\n",
        "config = {\n",
        "    \"image_size\": 224,\n",
        "    \"images_path\": \"timer_dataset/images\",\n",
        "    \"markup_path\": \"timer_dataset/targets.txt\",\n",
        "    \"splits_path\": \"timer_dataset/splits.json\",\n",
        "    \"batch_size\": 32,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"num_epochs\": 10,\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"backbone\": models.resnet152(weights=models.resnet.ResNet152_Weights.DEFAULT)\n",
        "}\n",
        "\n",
        "model = main(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Изначально я запустил свое ведро с lr = lr-10, одной эпохой и маленьким батч сайзом, получилась чепуха, решил теперь по другому"
      ],
      "metadata": {
        "id": "i51Ap-ffWiuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UPD: с батчем 32 и 25 эпохами я переобучился и мой лос оказался на дне, давайте внесем правки"
      ],
      "metadata": {
        "id": "x6PSwD2JZhDB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmzmk8peqI8b"
      },
      "source": [
        "### Save model's state dict: (if you wish)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "8PN1319RqBZ9"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48KIk7kgqNRg"
      },
      "source": [
        "## [Task 9] Model Inference - 0.5 Points\n",
        "\n",
        "### Description:\n",
        "Create a function to perform inference on a single image using a pre-trained model, converting the output to a human-readable time format.\n",
        "\n",
        "### Steps:\n",
        "1. Define an `infer_torch` function that accepts an image in numpy array format, the trained model, and the target image size for preprocessing.\n",
        "2. Inside the function, apply the necessary validation augmentations and preprocessing to prepare the image for the model.\n",
        "3. Convert the preprocessed image to a PyTorch tensor and feed it into the model to obtain the predicted hour and minute.\n",
        "4. Convert the model's output to a time string in the format 'HH:MM'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "aT8vcQ5HqOno"
      },
      "outputs": [],
      "source": [
        "def infer_torch(image: np.ndarray, model: torch.nn.Module, image_size=64) -> str:\n",
        "    \"\"\"\n",
        "    Performs inference on a single image using a trained model.\n",
        "\n",
        "    This function applies validation augmentations and preprocessing to the image, converts it to a\n",
        "    PyTorch tensor, and then uses the model to predict the time. The function outputs the predicted\n",
        "    time as a string.\n",
        "\n",
        "    Args:\n",
        "        image (np.ndarray): The image to be processed and fed into the model.\n",
        "        model (torch.nn.Module): The trained model used for inference.\n",
        "        image_size (int, optional): The size to which the image will be resized.\n",
        "\n",
        "    Returns:\n",
        "        str: The predicted time as a string in the format 'HH:MM'.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Apply validation augmentations\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "\n",
        "    # Preprocess the image\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "\n",
        "    # Convert the image to a PyTorch tensor, add batch dimension, put on device\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "\n",
        "    # Predict using the model\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "\n",
        "    # Convert to time format\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "\n",
        "def infer_torch(image: np.ndarray, model: torch.nn.Module, image_size=64) -> str:\n",
        "    model.eval()\n",
        "\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])\n",
        "\n",
        "    image = transform(image).to(\"cuda\")\n",
        "    image = image.unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hour_preds, minute_preds = model(image)\n",
        "\n",
        "    hour = hour_preds.argmax(1).item()\n",
        "    minute = minute_preds.argmax(1).item()\n",
        "    predicted_time = f'{hour:02d}:{minute:02d}'\n",
        "\n",
        "    return predicted_time\n"
      ],
      "metadata": {
        "id": "cGZPYGUvVA0D"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WVRExmkdu1m"
      },
      "source": [
        "### Testing:\n",
        "- Use a sample image and a trained model to test the `infer_torch` function.\n",
        "- Display the original image and the predicted time to verify the function's output."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_path = 'Example2.png'\n",
        "\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # convert to jpg\n",
        "\n",
        "predicted_time = infer_torch(image, model)\n",
        "\n",
        "def visualize(image):\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "visualize(image=image)\n",
        "print(\"Predicted Time:\", predicted_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "1wG4AlJVR5bA",
        "outputId": "30b24fd3-3e16-41ce-b4f0-4a99e94bcf62"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Time: 03:04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вау, после добавления нормализации в infer_torch распозналось. Поигрался с эпохами и батчем и на 7 запуск всё ок"
      ],
      "metadata": {
        "id": "-r_qB0nvTp32"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77w8e30PrP_p"
      },
      "source": [
        "## [Task 10] Model Evaluation - 1 Point\n",
        "\n",
        "### Description:\n",
        "Write a function to assess the model's performance on the validation set by calculating accuracy, which is the proportion of correct predictions to total predictions.\n",
        "\n",
        "### Steps:\n",
        "1. Define an `evaluate_model` function that receives the model, paths to splits and targets, and the directory containing images.\n",
        "2. Load the validation set splits and corresponding targets.\n",
        "3. Iterate over the validation set, performing inference and comparing the predicted time to the actual time.\n",
        "4. Tally the correct predictions and calculate the accuracy.\n",
        "\n",
        "**(!!) To achieve full points for this task, the model's accuracy on the validation set must exceed 0.9. Make sure to fine-tune your model and preprocessing steps to meet this benchmark.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpu1w9BJdu1m"
      },
      "source": [
        "**Two helper functions, special for you:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6JZOxzeqwuu"
      },
      "outputs": [],
      "source": [
        "def load_splits(splits_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Loads train/validation splits from a JSON file.\n",
        "\n",
        "    This function reads a JSON file specifying which images are in the training set\n",
        "    and which are in the validation set.\n",
        "\n",
        "    Args:\n",
        "        splits_path (str): The path to the JSON file containing the train/validation splits.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with keys 'train' and 'validation', each mapping to a list of image names.\n",
        "    \"\"\"\n",
        "    with open(splits_path, 'r') as file:\n",
        "        splits = json.load(file)\n",
        "    return splits\n",
        "\n",
        "\n",
        "def load_targets(targets_path: str) -> dict[str, str]:\n",
        "    \"\"\"\n",
        "    Loads target time labels for images from a file.\n",
        "\n",
        "    This function reads a file where each line contains a time label and an image name,\n",
        "    separated by ' -> '. It creates a dictionary mapping from image names to their corresponding\n",
        "    time labels.\n",
        "\n",
        "    Args:\n",
        "        targets_path (str): The path to the file containing the image names\n",
        "        and their corresponding time labels.\n",
        "\n",
        "    Returns:\n",
        "        dict[str, str]: A dictionary where keys are image names\n",
        "        and values are their corresponding time labels.\n",
        "    \"\"\"\n",
        "    targets = {}\n",
        "    with open(targets_path, 'r') as file:\n",
        "        for line in file:\n",
        "            time_str, image_name = line.strip().split(' -> ')\n",
        "            targets[image_name] = time_str\n",
        "    return targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vov61_I0rR1X"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "def evaluate_model(\n",
        "    model: torch.nn.Module,\n",
        "    splits_path: str,\n",
        "    targets_path: str,\n",
        "    images_dir: str,\n",
        "    image_size: int = 64\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Evaluates model's accuracy on a validation set.\n",
        "\n",
        "    This function calculates the accuracy of the provided model by comparing its predictions\n",
        "    with the actual target times for each image in the validation set. It uses a specified\n",
        "    splits file to determine the images in the validation set and a targets file to get the\n",
        "    correct time labels.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The trained model to evaluate.\n",
        "        splits_path (str): Path to the JSON file containing the train/validation splits.\n",
        "        targets_path (str): Path to the file containing the image names and their corresponding time labels.\n",
        "        images_dir (str): Directory containing the images referenced in the targets file.\n",
        "        image_size (int, optional): Size to which the images should be resized.\n",
        "\n",
        "    Returns:\n",
        "        float: The accuracy of the model on the validation set.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    splits = load_splits(splits_path)\n",
        "    targets = load_targets(targets_path)\n",
        "\n",
        "    # Metrics initialization\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "\n",
        "    # Calculate accuracy\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "    return accuracy\n",
        "\n",
        "splits_path = 'timer_dataset/splits.json'\n",
        "targets_path = 'timer_dataset/targets.txt'\n",
        "images_dir = 'timer_dataset/images/'\n",
        "\n",
        "accuracy = evaluate_model(model, splits_path, targets_path, images_dir)\n",
        "print(\"\\nAccuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYhsNEZbdu1n"
      },
      "outputs": [],
      "source": [
        "assert accuracy > 0.9, \"Try again!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSpK55pfdu1n"
      },
      "source": [
        "## [Task 11] Model Conversion and Speed Benchmarking - 1 Point\n",
        "\n",
        "### Description:\n",
        "Convert the trained model to different runtimes (JIT, ONNX, TensorRT) and benchmark the inference speed. Document the results in a comparative table.\n",
        "\n",
        "### Steps:\n",
        "1. Use the original PyTorch model (referred to as 'Vanilla') and perform inference speed testing.\n",
        "2. Convert the model using JIT compilation and measure the inference speed.\n",
        "3. Use the Torch Compile API to compile the model and benchmark the speed.\n",
        "4. Convert the model to TensorRT and test inference speed.\n",
        "5. Convert the model to ONNX and test inference speed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxr3akTsrqGg"
      },
      "source": [
        "**Vanilla**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c59VXLp2Gfl"
      },
      "outputs": [],
      "source": [
        "# Ensure, that the model in eval() mode, put it on the device\n",
        "model = # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I_C8bSBrVoX"
      },
      "outputs": [],
      "source": [
        "%%timeit -n 500\n",
        "image = # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "infer_torch(image, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc_39gQy3QPs"
      },
      "source": [
        "**Jit Tracing**\n",
        "\n",
        "Torch JIT tracing converts PyTorch models into an optimized, platform-independent format, boosting performance and simplifying deployment. It's useful for efficiently running models across different devices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MafeaWsG03n4"
      },
      "outputs": [],
      "source": [
        "# Create a dummy input for the tracing\n",
        "# ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "\n",
        "# Trace the model\n",
        "# ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42a-qoF73bhS"
      },
      "outputs": [],
      "source": [
        "%%timeit -n 500\n",
        "image = # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "infer_torch(image, traced_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bajcqt3_rzon"
      },
      "source": [
        "**Torch Compile**\n",
        "\n",
        "`torch.compile` is a PyTorch feature that enhances performance by JIT-compiling PyTorch code into optimized kernels. This method speeds up code execution significantly with minimal changes to the existing codebase. It's a step beyond previous PyTorch compiler solutions like TorchScript and FX Tracing, offering more streamlined and efficient optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv_obvHwr6SZ"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "opt_model = # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-w4JGdsr_74"
      },
      "outputs": [],
      "source": [
        "%%timeit -n 500\n",
        "image = # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "infer_torch(image, opt_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpxhTy663w0W"
      },
      "source": [
        "**TensorRT**\n",
        "\n",
        "`TensorRT`, developed by NVIDIA, significantly enhances the speed and efficiency of deep learning models on GPUs. It uses advanced optimization techniques such as layer fusion and precision calibration to maximize throughput and reduce latency. Designed for cross-platform compatibility, it supports various frameworks and is particularly effective in production environments where high-performance inference is crucial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4kgYqV64Deq"
      },
      "outputs": [],
      "source": [
        "import torch_tensorrt\n",
        "\n",
        "# Create a dummy input for the compile\n",
        "dummy_input = # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "\n",
        "# Compile the model\n",
        "tensorrt_model = # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uc8psUc5WM2"
      },
      "outputs": [],
      "source": [
        "%%timeit -n 500\n",
        "image = # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "infer_torch(image, tensorrt_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqX8i-UN9Owb"
      },
      "source": [
        "**ONNX**\n",
        "\n",
        "`ONNX (Open Neural Network Exchange)` is an open format designed to represent machine learning models. It enables models to be transferred between different frameworks, ensuring interoperability and flexibility. ONNX is widely used for model sharing and deployment across various platforms and tools, making it valuable for developers working in diverse environments or with multiple machine learning frameworks. Its ability to standardize model representation simplifies the process of model exchange and deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJ1-Ykq39InI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.onnx\n",
        "\n",
        "# Create a dummy input for the export\n",
        "dummy_input = # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "\n",
        "# Export the model, saving it like \"model.onnx\"\n",
        "# ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXbdtezB-hFb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "\n",
        "\n",
        "def infer_onnx(\n",
        "    image: np.ndarray,\n",
        "    session: ort.InferenceSession,\n",
        "    image_size: int = 64\n",
        "  ) -> str:\n",
        "    \"\"\"\n",
        "    Performs inference on a single image using an ONNX model session.\n",
        "\n",
        "    This function applies validation augmentations and preprocessing to the image, converts it to the\n",
        "    format expected by the ONNX model, and then uses the session to predict the time. The function\n",
        "    outputs the predicted time as a string.\n",
        "\n",
        "    Args:\n",
        "        image (np.ndarray): The image to be processed and fed into the ONNX model.\n",
        "        session (ort.InferenceSession): The ONNX model inference session.\n",
        "        image_size (int, optional): The size to which the image will be resized.\n",
        "\n",
        "    Returns:\n",
        "        str: The predicted time as a string in the format 'HH:MM'.\n",
        "    \"\"\"\n",
        "    # Get ONNX model input_name\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "\n",
        "    # Apply validation augmentations\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "\n",
        "    # Preprocess the image\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "\n",
        "    # Convert the image to the batch expected by ONNX, cast to float\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "\n",
        "    # Predict using the ONNX session\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "\n",
        "    # Assuming the model returns two outputs: hour and minute\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "\n",
        "    # Convert to time format\n",
        "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "    return time_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0jHJv23GM9D"
      },
      "outputs": [],
      "source": [
        "# We initialize a session first\n",
        "session = ort.InferenceSession(\"model.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H7yiLncCQ_-"
      },
      "outputs": [],
      "source": [
        "%%timeit -n 500\n",
        "image = # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ YOUR CODE HERE\n",
        "infer_onnx(image, session=session)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5o5wGqfdu1o"
      },
      "source": [
        "### Fill the table:\n",
        "\n",
        "| Runtime   | Number of Loops | Mean Inference Time (ms) | Standard Deviation (ms) |\n",
        "|-----------|-----------------|--------------------------|-------------------------|\n",
        "| Vanilla   | 500             | TBD                      | TBD                     |\n",
        "| JIT       | 500             | TBD                      | TBD                     |\n",
        "| Compile   | 500             | TBD                      | TBD                     |\n",
        "| TensorRT  | 500             | TBD                      | TBD                     |\n",
        "| ONNX      | 500             | TBD                      | TBD                     |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgQOQBv6du1o"
      },
      "source": [
        "### Your comments on results:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSI8Pwgcdu1o"
      },
      "source": [
        "(0_0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBKQvEW8SpLC"
      },
      "source": [
        "## [Task 12] Rust - 3 Points\n",
        "\n",
        "<img src=\"./images/4.jpeg\" width=50%>\n",
        "\n",
        "### About Rust:\n",
        "Rust is a programming language known for its focus on safety and performance. It's designed to be memory safe, preventing common bugs seen in languages like C and C++. Rust achieves this through its unique ownership system, which manages memory and other resources at compile time, eliminating many runtime errors.\n",
        "\n",
        "Its performance is comparable to C++, making it suitable for systems programming and applications where speed is critical. Rust also offers modern features like zero-cost abstractions, guaranteed memory safety, and a friendly compiler with useful error messages, enhancing developer experience.\n",
        "\n",
        "Rust is increasingly popular in areas such as web assembly, embedded systems, and networking, as well as for building command-line tools and desktop applications. Its growing community and rich ecosystem of tools and libraries contribute to its rising adoption.\n",
        "\n",
        "\n",
        "### Suggested Materials:\n",
        "- \"Rust by Example\": A collection of runnable examples that illustrate various Rust concepts and standard libraries.\n",
        "- \"Rustlings\": A fun, instructive way to get accustomed to reading and writing Rust syntax through small exercises.\n",
        "- \"Maturin\": A tool specifically designed for creating Python extensions in Rust with ease. It integrates seamlessly with Cargo and PyPI, simplifying the process of building and distributing Rust-written Python modules. Ideal for enhancing Python with Rust’s performance and safety features, Maturin makes it straightforward to package and share Rust code as Python packages.\n",
        "\n",
        "### Why Infer in Rust:\n",
        "Rust is good for machine learning inference, offering safety and high performance. It avoids latency issues common with garbage collectors and its type system and concurrency model enable efficient, maintainable code. Rust's capabilities allow for serverless inference with lightweight binaries, addressing the slowness of large frameworks like PyTorch in cluster instances. It also reduces Python's performance overhead, a notable advantage given Python's Global Interpreter Lock (GIL) challenges. Rust's growing popularity in the machine learning ecosystem.\n",
        "\n",
        "Finally, Rust is cool!\n",
        "\n",
        "---\n",
        "\n",
        "### Description:\n",
        "The task involves enhancing a machine learning workflow by integrating Rust's performance capabilities with Python's flexibility. The goal is to use Rust for running an ONNX model inference, and then create Python bindings to utilize the Rust implementation. This hybrid approach aims to leverage Rust's performance and safety while maintaining the ease of use provided by Python.\n",
        "\n",
        "The project structure includes:\n",
        "```\n",
        ".\n",
        "├── Cargo.toml\n",
        "├── images\n",
        "├── HW6.ipynb\n",
        "├── model.onnx\n",
        "├── example.png\n",
        "├── src\n",
        "│   ├── lib.rs\n",
        "│   └── main.rs\n",
        "└── timer_dataset\n",
        "```\n",
        "\n",
        "- An example image file `example.png` which could be used for testing the inference process.\n",
        "- A `model.onnx` file which is our converted model to be used for inference.\n",
        "- A `Cargo.toml` file indicating the Rust project's dependencies.\n",
        "- A source directory `src` containing the Rust source code:\n",
        "  - `lib.rs` which is a Rust library file containing shared logic or definitions.\n",
        "  - `main.rs` which is the Rust main file, containing the entry point of the Rust application.\n",
        "\n",
        "**The `.rs` files in the source directory are almost complete but contain errors that need to be fixed. After correcting these errors, you are expected to compile the Rust source into a binary. This binary will be a production-ready executable that performs the ONNX model inference.**\n",
        "\n",
        "**The second part of the task is to build Python bindings using `maturin`. These bindings will allow Python scripts to call the Rust binary and perform inference. The binding should provide an interface where Python code can pass the paths of the model and image files, and then receive the inference results. The results expected are a string representing the predicted outcome and a float64 value indicating the elapsed time of the model call in Rust.**\n",
        "\n",
        "### Steps:\n",
        "1. Debug and correct the Rust code provided in `.rs` files.\n",
        "2. Compile the corrected Rust code into a production-ready binary for ONNX model inference.\n",
        "3. Create Python bindings for the Rust binary to allow inference from Python, ensuring the binding returns the predicted time as a string and the elapsed time as a float64."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOMdSMvidu1o"
      },
      "source": [
        "### Part 1: Binary - 1 Point\n",
        "\n",
        "Compile a Rust binary that performs ONNX model inference and accurately predicts time from an image.\n",
        "\n",
        "Instructions:\n",
        "1. Compile the Rust binary using the provided command. Ensure all dependencies are correctly installed for a successful build.\n",
        "2. Run the binary with an image to perform inference. The program should output the time taken for inference and the predicted time.\n",
        "\n",
        "Criteria for Full Points:\n",
        " - The Rust binary compiles without errors.\n",
        " - Upon execution, the binary prints out the time taken for the inference process and the correct predicted time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqxt8F9UL3Ch"
      },
      "outputs": [],
      "source": [
        "!cargo build --bin binary -r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qGSDEwSYB08"
      },
      "outputs": [],
      "source": [
        "!./target/release/binary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEobhMEvdu1o"
      },
      "source": [
        "### Part 2: Python Binding - 2 Points\n",
        "\n",
        "Build a Python binding for the Rust-based ONNX inference engine and validate its functionality through a Python interface.\n",
        "\n",
        "Instructions:\n",
        "1. Use maturin to build the Python binding from the Rust implementation.\n",
        "2. Install the generated wheel using pip to make the binding available to Python.\n",
        "3. In Python, import the provided binding function and pass the paths of the ONNX model and an image file to it.\n",
        "4. Check that the function returns the correct prediction and the model's call time measured in Rust.\n",
        "\n",
        "Criteria for Full Points:\n",
        " - The Python binding compiles and installs without errors.\n",
        " - The Python code successfully calls the Rust inference engine and returns the correct prediction and elapsed time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmCJvcGgdu1o"
      },
      "source": [
        "**Binding build and library install:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPOCxt4vbsbx"
      },
      "outputs": [],
      "source": [
        "!maturin build -r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3tMxYuobzRX"
      },
      "outputs": [],
      "source": [
        "!pip install # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMQiPWWsdu1p"
      },
      "source": [
        "**Binding test:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hicxOvOkfZ-9"
      },
      "outputs": [],
      "source": [
        "from onnx_inference import run_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCQxriGefeRd"
      },
      "outputs": [],
      "source": [
        "predict, elapsed_time = run_model(\"model.onnx\", \"example.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kau4g_Atdu1p"
      },
      "outputs": [],
      "source": [
        "print(\"Time:\", predict, \"\\nElapsed time:\", elapsed_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM9JLQD0du1p"
      },
      "outputs": [],
      "source": [
        "assert predict == \"15:53\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwuHVZEmdu1p"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}